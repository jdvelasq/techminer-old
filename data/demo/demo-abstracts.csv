Link,Abstract,Author Keywords,Index Keywords
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034773068&doi=10.3390%2fsym9110283&partnerID=40&md5=40838d250615bc05ce2d3c76af4b9498","The importance of an interference-less machine learning scheme in time series prediction is crucial, as an oversight can have a negative cumulative effect, especially when predicting many steps ahead of the currently available data. The on-going research on noise elimination in time series forecasting has led to a successful approach of decomposing the data sequence into component trends to identify noise-inducing information. The empirical mode decomposition method separates the time series/signal into a set of intrinsic mode functions ranging from high to low frequencies, which can be summed up to reconstruct the original data. The usual assumption that random noises are only contained in the high-frequency component has been shown not to be the case, as observed in our previous findings. The results from that experiment reveal that noise can be present in a low frequency component, and this motivates the newly-proposed algorithm. Additionally, to prevent the erosion of periodic trends and patterns within the series, we perform the learning of local and global trends separately in a hierarchical manner which succeeds in detecting and eliminating short/long term noise. The algorithm is tested on four datasets from financial market data and physical science data. The simulation results are compared with the conventional and state-of-the-art approaches for time series machine learning, such as the non-linear autoregressive neural network and the long short-term memory recurrent neural network, respectively. Statistically significant performance gains are recorded when the meta-learning algorithm for noise reduction is used in combination with these artificial neural networks. For time series data which cannot be decomposed into meaningful trends, applying the moving average method to create meta-information for guiding the learning process is still better than the traditional approach. Therefore, this new approach is applicable to the forecasting of time series with a low signal to noise ratio, with a potential to scale adequately in a multi-cluster system due to the parallelized nature of the algorithm. © 2017 by the authors.","Component trends; Empirical mode decomposition; Interference-less machine learning; Long short-term memory; Meta-learning; Moving average; Noise reduction; Nonlinear autoregressive neural network; Time series forecasting",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987989524&doi=10.1109%2fICIS.2016.7550882&partnerID=40&md5=f7152445d8858e9425db76f90ec140c6","This paper proposes a novel application of deep learning models, Paragraph Vector, and Long Short-Term Memory (LSTM), to financial time series forecasting. Investors make decisions according to various factors, including consumer price index, price-earnings ratio, and miscellaneous events reported in newspapers. In order to assist their decisions in a timely manner, many automatic ways to analyze those information have been proposed in the last decade. However, many of them used either numerical or textual information, but not both for a single company. In this paper, we propose an approach that converts newspaper articles into their distributed representations via Paragraph Vector and models the temporal effects of past events on opening prices about multiple companies with LSTM. The performance of the proposed approach is demonstrated on real-world data of fifty companies listed on Tokyo Stock Exchange. © 2016 IEEE.",,"Earnings; Financial data processing; Information science; Newsprint; Consumer price index; Distributed representation; Financial time series forecasting; Long short term memory; Novel applications; Stock predictions; Textual information; Tokyo Stock Exchange; Costs"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958535711&doi=10.1007%2f978-3-319-09330-7_8&partnerID=40&md5=ffad3cd6cbb8da2dd239cf680f520fc0","A novel type of recurrent neural network, the regularized Dynamic Self Organised Neural Network Inspired by the Immune Algorithm, is presented. The Regularization technique is used with the Dynamic self-organized multilayer perceptrons network that is inspired by the immune algorithm. The regularization has been addressed to improve the generalization and to solve the over-fitting problem. The results of an average 30 simulations generated from ten stationary signals are demonstrates. The results of the proposed network were compared with the regularized multilayer neural networks and the regularized self organized neural network inspired by the immune algorithm. The simulation results indicated that the proposed network showed better values in terms of the annualized return in comparison to the benchmarked networks. © 2014 Springer International Publishing Switzerland.","And financial time series prediction; Dynamic neural network; Exchange rate time series","Bioinformatics; Financial data processing; Intelligent computing; Multilayer neural networks; Recurrent neural networks; Dynamic neural networks; Exchange rates; Financial time series predictions; Immune algorithms; Regularization technique; Self-organised; Self-organized neural networks; Stationary signal; Algorithms"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058627874&doi=10.1145%2f3277104.3277120&partnerID=40&md5=57398d936e3cb9aec0619c8188b9e77e","Computational technologies have offered faster and efficient solutions to many diverse areas including the financial sector. In the financial market, the advancements in computational field have been mainly achieved through the use of neural networks and machine learning tools that delivered a number of financial applications. These applications include: stock market prediction, bankruptcy prediction, risk assessment etc. Thus, in this paper, we are developing a technique to predict the stock market index for the “Dow Jones” using deep learning algorithms. We propose a model based on an adaptive NARX neural network that can predict the closing price of a moderately stable market. In our model, non-linear auto regressive exogenous input model inserts delays into the input as well as the output acting as memory slots thereby raising the accuracy of the prediction. This model uses a time series analysis to improve the prediction accuracy. In addition, Levenberg-Marquardt algorithm has been used for training the network. The accuracy of the model is determined by the mean squared error between the predicted and the actual prices. © 2018 Association for Computing Machinery.","Artificial intelligence; Deep learning; Financial forecasting; NARX algorithm; Stock prediction","Artificial intelligence; Big data; Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Mean square error; Risk assessment; Time series analysis; Auto-regressive exogenous inputs; Bankruptcy prediction; Computational technology; Financial applications; Financial forecasting; Levenberg-Marquardt algorithm; Stock market prediction; Stock predictions; Learning algorithms"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061485605&doi=10.1109%2fNCG.2018.8593076&partnerID=40&md5=1800fd3a7bac4080c421c563152a90a5","Deep learning has recently received growing interest and attention. It has been successfully applied to many fields. Stock market time-series forecasting is one the most challenging problems for a variety of learning methodologies. In this paper, we studied the integration of deep learning methodologies into stock market forecasting. We evaluated and compared a number of variants of Deep Recurrent Neural Network based on LSTM and GRU. Both bidirectional and unidirectional stacked architectures with multivariate inputs were employed to perform short- and long-term forecasting. The deep learning architectures were also compared to shallow neural networks using S P500 index historical data. It has been noticed that a stacked LSTM architecture has demonstrated the highest forecasting performance for both short- and long-term. © 2018 IEEE.",,"Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Multivariant analysis; Network architecture; Forecasting performance; Historical data; Learning architectures; Long-term forecasting; Market forecast; Multi variate analysis; Stock market forecasting; Time series forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049058462&doi=10.1007%2f978-3-319-93701-4_29&partnerID=40&md5=cfb5d82e2667813903d00f48094cef66","This paper presents improvements in financial time series prediction using a Deep Neural Network (DNN) in conjunction with a Discrete Wavelet Transform (DWT). When comparing our model to other three alternatives, including ARIMA and other deep learning topologies, ours has a better performance. All of the experiments were conducted on High-Frequency Data (HFD). Given the fact that DWT decomposes signals in terms of frequency and time, we expect this transformation will make a better representation of the sequential behavior of high-frequency data. The input data for every experiment consists of 27 variables: The last 3 one-minute pseudo-log-returns and last 3 one-minute compressed tick-by-tick wavelet vectors, each vector is a product of compressing the tick-by-tick transactions inside a particular minute using a DWT with length 8. Furthermore, the DNN predicts the next one-minute pseudo-log-return that can be transformed into the next predicted one-minute average price. For testing purposes, we use tick-by-tick data of 19 companies in the Dow Jones Industrial Average Index (DJIA), from January 2015 to July 2017. The proposed DNN’s Directional Accuracy (DA) presents a remarkable forecasting performance ranging from 64% to 72%. © Springer International Publishing AG, part of Springer Nature 2018.","Computational finance; Deep Neural Networks; Discrete Wavelet Transform; High-frequency forecasting; Short-term forecasting","Discrete wavelet transforms; Financial data processing; Forecasting; Metadata; Signal reconstruction; Topology; Computational finance; Directional accuracy; Dow Jones Industrial averages; Financial time series predictions; Forecasting performance; High frequency data; High frequency HF; Short-term forecasting; Deep neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064841438&doi=10.1007%2fs00500-019-04006-2&partnerID=40&md5=2639fa521ccb02834040e5c254070614","In this paper, we develop a new Hybrid method based on machine learning algorithms for jump detection in financial time series. Jump is an important behavior in financial time series, since it implies a change in volatility. Ones can buy the volatility instrument if ones expect the volatility will bloom up in the future. A jump detection model attempts to detect short-term market instability, since it could be jumping up or down, instead of a directional prediction. The directional prediction can be considered as a momentum or trend following, which is not the focus of this paper. A jump detection model is commonly applied in a systematic fast-moving strategy, which reallocates the assets automatically. Also, a systematic opening position protection strategy can be driven by a jump detection model. For example, for a tail risk protection strategy, a pair of long call and put option order could be placed in the same time, in order to protect the open position given a huge change in volatility. One of the key differentiations of the proposed model with the classical methods of time-series anomaly detection is that, jump threshold parameters are not required to be predefined in our proposed model. Also the model is a combination of a Long short-term memory (LSTM) neural network model and a machine learning pattern recognition model. The LSTM model is applied for time series prediction, which predicts the next data point. The historical prediction errors sequence can be used as the information source or input of the jump detection model/module. The machine learning pattern recognition model is applied for jump detection. The combined model attempts to determine whether the current data point is a jump or not. LSTM neural network is a type of Recurrent Neural Networks (RNNs). LSTM records not only the recent market, but also the historical status. A stacked RNN is trained on a dataset which is mixed with normal and anomalous data. We compare the performance of the proposed Hybrid jump detection model and different pattern classification algorithms, such as k-nearest neighbors algorithm identifier, Hampel identifier, and Lee Mykland test. The model is trained and tested using real financial market data, including 11 global stock market in both developed and emerging markets in US, China, Hong Kong, Taiwan, Japan, UK, German, and Israel. The experiment result shows that the proposed Hybrid jump detection model is effective to detect jumps in terms of accuracy, comparing to the other classical jump detection methods. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Anomaly detection; Long short-term memory (LSTM) neural network; Machine learning; Recurrent neural network","Anomaly detection; Binary alloys; Brain; Commerce; Electronic trading; Financial markets; Forecasting; Learning algorithms; Learning systems; Machine learning; Nearest neighbor search; Pattern recognition; Potassium alloys; Recurrent neural networks; Time series; Uranium alloys; Classification algorithm; Directional predictions; Financial time series; Global stock markets; Neural network model; Recurrent neural network (RNNs); Threshold parameters; Time series prediction; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049969159&doi=10.1016%2fj.eswa.2018.07.019&partnerID=40&md5=08712e647976ca327f91763d9bce54a9","Forecasting a financial asset's price is important as one can lower the risk of investment decision- making with accurate forecasts. Recently, the deep neural network is popularly applied in this area of research; however, it is prone to overfitting owing to limited availability of data points for training. We propose a novel data augmentation approach for stock market index forecasting through our ModAugNet framework, which consists of two modules: an overfitting prevention LSTM module and a prediction LSTM module. The performance of the proposed model is evaluated using two different representative stock market data (S&P500 and Korea Composite Stock Price Index 200 (KOSPI200)). The results confirm the excellent forecasting accuracy of the proposed model. ModAugNet-c yields a lower test error than the comparative model (SingleNet) in which an overfitting prevention LSTM module is absent. The test mean squared error (MSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for S&P500 decreased to 54.1%, 35.5%, and 32.7%, respectively, of the corresponding S&P500 forecasting errors of SingleNet, while the same for KOSPI200 decreased to 48%, 23.9%, and 32.7%, respectively, of the corresponding KOSPI200 forecasting errors of SingleNet. Furthermore, through the analyses of the trained ModAugNet-c, we found that test performance is entirely dependent on the prediction LSTM module. The contribution of this study is its applicability in various instances where it is challenging to artificially augment data, such as medical data analysis and financial time-series modeling. © 2018 Elsevier Ltd","Data augmentation; Deep learning; Long short-term memory; Overfitting; Stock market index","Commerce; Decision making; Deep learning; Deep neural networks; Errors; Financial data processing; Financial markets; Forecasting; Investments; Mean square error; Time series analysis; Data augmentation; Financial time series; Investment decision making; Mean absolute percentage error; Medical data analysis; Overfitting; Overfitting preventions; Stock market index; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052879308&doi=10.1007%2f978-3-319-98539-8_26&partnerID=40&md5=1945e8be827380f8765aabcc65d5dc1a","Most approaches to forecasting time series data employ one-step-ahead prediction approaches. However, recently there has been focus on multi-step-ahead prediction approaches. These approaches demonstrate enhanced prediction capabilities. However, multi-step-ahead prediction increases the complexity of the prediction process in comparison to one-step-ahead approaches. Typically, studies in the examination of multi-step ahead methods have addressed issues such as the increased complexity, inaccuracy, uncertainty, and error variance on the prediction horizon, and have been deployed in various domains such as finance, economics, agriculture and hydrology. When determining which algorithm to use in a time series analyses, the approach is to analyze the series for numerous characteristics and features, such as heteroscedasticity, auto-correlation, seasonality and stationarity. In this work, a comparative analysis of 20 different time series datasets is presented and a demonstration of the complexity in deciding which approach to use is given. The study investigates some of the main prediction approaches such as ARIMA (Autoregressive integrated moving average), NN (Neural Network), RNN (Recurrent neural network) and SVR (Support vector regression), which focus on the recursive prediction strategy and compare them to a new approach known as MRFA (Multi-Resolution Forecast Aggregation). © Springer Nature Switzerland AG 2018.",,"Complex networks; Data mining; Economics; Forecasting; Recurrent neural networks; Time series; Time series analysis; Algorithmic approach; Auto-regressive integrated moving average; Comparative analysis; Forecasting time series; Multi-step-ahead predictions; Prediction capability; Recursive prediction; Support vector regression (SVR); Big data"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943244653&doi=10.1080%2f18756891.2015.1099910&partnerID=40&md5=18349a63ec6b83e487ad63a0d96a223e","A low complexity Polynomial Functional link Artificial Recurrent Neural Network (PFLARNN) has been proposed for the prediction of financial time series data. Although different types of polynomial functions have been used for low complexity neural network architectures earlier for stock market prediction, a comparative study is needed to choose the optimal combinations of the nonlinear functions for a reasonably accurate forecast. Further a recurrent version of the Functional link neural network is used to model more accurately a chaotic time series like stock market indices with a lesser number of nonlinear basis functions. The proposed PFLARNN model when trained with the well known gradient descent algorithm produces reasonable accuracy with a choice of range of weight parameters of the network. However, to improve the accuracy of the forecast further, the weight parameters of the recurrent functional neural network are optimized using an evolutionary learning algorithm like the differential evolution (DE). A comparison with other well known neural architectures shows that the proposed low complexity neural model can provide significant prediction accuracy for one day advance and speed of convergence using the International Business Machines Corp. (IBM) stock market indices. © 2015 the authors.","AMAPE; backpropagation learning algorithm; differential evolution; IBM stock indices; MAPE; PFLARNN; Polynomial functions","Algorithms; Backpropagation; Backpropagation algorithms; Commerce; Complex networks; Evolutionary algorithms; Finance; Financial data processing; Financial markets; Forecasting; Functions; Learning algorithms; Network architecture; Neural networks; Optimization; Parameter estimation; Polynomials; Recurrent neural networks; Time series; AMAPE; Backpropagation learning algorithm; Differential Evolution; Mape; PFLARNN; Polynomial functions; Stock indices; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887614624&doi=10.1016%2fj.rfe.2013.05.005&partnerID=40&md5=ce7ed29c8dafbcd2bae5d08f3be9a92b","Opponents of the efficient markets hypothesis argue that predictability reflects the psychological factors and ""fads"" of irrational investors in a speculative market. In that, conventional time series analysis often fails to give an accurate forecast for financial processes due to inherent noise patterns, fat tails, and nonlinear components. A recent stream of literature on behavioral finance has revealed that boundedly rational agents using simple rules of thumb for their decisions under uncertainty provides a more realistic description of human behavior than perfect rationality with optimal decision rules. Consequently, the application of technical analysis in trading could produce high returns. Machine learning techniques have been employed in economic systems in modeling nonlinearities and simulating human behavior. In this study, we expand the literature that evaluates return sign forecasting ability by introducing a recurrent neural network approach that combines heuristic learning and short-term memory emulation, thus mimicking the decision-making process of boundedly rational agents. We investigate the relative direction-of-change predictability of the neural network structure implied by the Lee-White-Granger test as well as compare it to other well-established models for the DJIA index. Moreover, we examine the relationship between stock return volatility and returns. Overall, the proposed model presents high profitability, in particular during ""bear"" market periods. © 2013 Elsevier Inc.","Machine learning; Neural networks; Stock predictability; Volatility trading",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062668948&doi=10.1016%2fj.procs.2019.01.008&partnerID=40&md5=714d8f4d5e93b00d91cefffe59bfdbf8","Time series analysis is an important field that, recently, captivate researchers attention. It represents a lot of real problems, one of them is the prediction of the stock prices. As known, the recurrent neural network (RNN) is the most used model for the prediction problem, since it gives good results for time series forecasting. This paper aims to forecast the stock price of Total Maroc for 29 days from Casablanca Stock Exchange, using principal component analysis (PCA) in order to reduce the number of features from eight to six. The use of dimensionality reduction enhances the accuracy of the recurrent neural network model and gives a good prediction for the stock price. © 2019 The Authors.","Forecasting Stock Prices; Principal Component Analysis; Recurrent Neural Network","Costs; Electronic trading; Financial markets; Forecasting; Intelligent computing; Recurrent neural networks; Time series analysis; Dimensionality reduction; Forecasting stock prices; Prediction problem; Real problems; Recurrent neural network (RNN); Recurrent neural network model; Stock exchange; Time series forecasting; Principal component analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065917523&doi=10.1007%2f978-3-030-19810-7_27&partnerID=40&md5=29e9d2d2190476b887ccdd0a100b5fbb","In recent years the advancement in neural network architecture and introduction of recurrent neural network has attracted a lot of interest to work with sequence data. LSTM is derived from the basic architecture of Recurrent Neural Network. It has memory units which extends the power of Recurrent Neural Network. In this paper, we analyze the performance of different advanced neural network architectures and classical time series forecasting method, e.g., ARIMA on selective stock prices from Dhaka Stock Exchange (DSE). Our experimental results show that the neural network models perform better than the ARIMA model in reducing RMSE (Root Mean Square Error). © Springer Nature Switzerland AG 2019.","ARIMA model; Gated recurrent unit; Long short term memory; Recurrent neural network; Stock price forecasting; Time series forecasting","Electronic trading; Financial markets; Forecasting; Long short-term memory; Mean square error; Memory architecture; Recurrent neural networks; Time series; ARIMA modeling; Financial forecasting; Gated recurrent unit; Performance analysis; RMSE (root mean square error); Statistical modeling; Stock price forecasting; Time series forecasting; Network architecture"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065197924&doi=10.21314%2fJCF.2018.358&partnerID=40&md5=5221681d4dc69884c3c16523563360d0","We present a method for conditional time series forecasting based on an adaptation of the recent deep convolutional WaveNet architecture. The proposed network contains stacks of dilated convolutions that allow it to access a broad range of historical data when forecasting. It also uses a rectified linear unit (ReLU) activation function, and conditioning is performed by applying multiple convolutional filters in parallel to separate time series, which allows for the fast processing of data and the exploitation of the correlation structure between the multivariate time series. We test and analyze the performance of the convolutional network both unconditionally and conditionally for financial time series forecasting using the Standard & Poor’s 500 index, the volatility index, the Chicago Board Options Exchange interest rate and several exchange rates, and we extensively compare its performance with those of the well-known autoregressive model and a long short-term memory network. We show that a convolutional network is well suited to regression-type problems and is able to effectively learn dependencies in and between the series without the need for long historical time series, that it is a time-efficient and easy-to-implement alternative to recurrent-type networks, and that it tends to outperform linear and recurrent models. © Infopro Digital Limited 2019. All rights reserved.","Convolutional neural network (CNN); Deep learning; Financial time series; Forecasting; Multivariate time series",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034213008&doi=10.1007%2f978-3-319-68612-7&partnerID=40&md5=39baac8a922fc20224c92664d71a4919","Forecasting financial time series using past observations has been a significant topic of interest. While temporal relationships in the data exist, they are difficult to analyze and predict accurately due to the non-linear trends and noise present in the series. We propose to learn these dependencies by a convolutional neural network. In particular the focus is on multivariate time series forecasting. Effectively, we use multiple financial time series as input in the neural network, thus conditioning the forecast of a time series x(t) on both its own history as well as that of a second (or third) time series y(t). Training a model on multiple stock series allows the network to exploit the correlation structure between these series so that the network can learn the market dynamics in shorter sequences of data. We show that long-term temporal dependencies in and between financial time series can be learned by means of a deep convolutional neural network based on the WaveNet model [2]. The network makes use of dilated convolutions applied to multiple time series so that the receptive field of the network is wide enough to learn both short and long-term dependencies. The architecture includes batch normalization and uses a 1 × k convolution with parametrized skip connections from the input time series as well as the time series we condition on, in this way learning long-term interdependencies in an efficient manner [1]. This improves the forecast, while at the same time limiting the requirement for a long historical price series and reducing the noise. Knowing the strong performance of CNNs on classification problems we show that they can be applied successfully to forecasting financial time series, without the need of large samples of data. We compare the performance of the WaveNet model to a state-of-the-art fully convolutional network (FCN), and an autoregressive model popular in econometrics and show that our model is much better able to learn important dependencies in between financial time series resulting in a more robust and accurate forecast. © Springer International Publishing AG 2017.","Convolutional neural network; Financial time series","Convolution; Deep neural networks; Economics; Finance; Financial data processing; Forecasting; Learning systems; Neural networks; Statistics; Auto regressive models; Convolutional neural network; Financial time series; Forecasting financial time series; Long-term dependencies; Multivariate time series; Temporal relationships; Time series forecasting; Time series"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061131265&doi=10.1007%2f978-3-030-10997-4_20&partnerID=40&md5=32d934560dd38fe2c4cc969c099ca107","Deep Learning is a consolidated, state-of-the-art Machine Learning tool to fit a function (Formula Presented) when provided with large data sets of examples (Formula Presented). However, in regression tasks, the straightforward application of Deep Learning models provides a point estimate of the target. In addition, the model does not take into account the uncertainty of a prediction. This represents a great limitation for tasks where communicating an erroneous prediction carries a risk. In this paper we tackle a real-world problem of forecasting impending financial expenses and incomings of customers, while displaying predictable monetary amounts on a mobile app. In this context, we investigate if we would obtain an advantage by applying Deep Learning models with a Heteroscedastic model of the variance of a network’s output. Experimentally, we achieve a higher accuracy than non-trivial baselines. More importantly, we introduce a mechanism to discard low-confidence predictions, which means that they will not be visible to users. This should help enhance the user experience of our product. © 2019, Springer Nature Switzerland AG.","Aleatoric models; Deep Learning; Time-series; Uncertainty","Forecasting; Machine learning; Time series; Uncertainty analysis; Confidence predictions; Heteroscedastic; Learning models; Real-world problem; State of the art; Uncertainty; Uncertainty modelling; User experience; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021906449&doi=10.1007%2f978-3-319-60438-1_69&partnerID=40&md5=b9e644aee3cbd114a691f74427e1b1b4","Predicting the future value of the stock is very difficult task, mostly because of a number of variables that need to be taken into account. This paper tackles problem of stock market predicting feasibility, especially when predictions are based only on a subset of available information, namely: financial experts’ recommendations. Analysis was based on data and results from ISMIS 2017 Data Mining Competition. An original method was proposed and evaluated. Participants managed to perform substantially better than random guessing, but no participant outperformed baseline solution. © Springer International Publishing AG 2017.","Artificial neural networks; Recurrent neural networks; Sequence modeling; Stock exchange; Time series prediction","Electronic trading; Financial markets; Forecasting; Intelligent systems; Neural networks; Expert recommendations; Financial experts; Sequence modeling; Stock exchange; Time series prediction; Recurrent neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882350479&doi=10.1007%2fs11227-012-0827-1&partnerID=40&md5=663588f686a46a9c7da0f8aaad27fffa","Forecasting volatility is an important issue in financial econometric analysis. This paper aims to seek a computationally feasible approach for predicting large scale conditional volatility and covariance of financial time series. In the case of multi-variant time series, the volatility is represented by a Conditional Covariance Matrix (CCM). Traditional models for predicting CCM such as GARCH models are incapable of dealing with high-dimensional cases as there are O(N 2) parameters to be estimated in the case of N-variant asset return, and it is difficult to accelerate the computation of estimating these parameters by utilizing modern multi-core architecture. These GARCH models also have difficulties in modeling non-linear properties. The widely used Restricted Boltzmann Machine (RBM) is an energy-based stochastic recurrent neural network and its extended model, Conditional RBM (CRBM), has shown its capability in modeling high-dimensional time series. In this paper, we first propose a CRBM-based approach to forecast CCM and show how to capture the long memory properties in volatility, and then we implement the proposed model on GPU by using CUDA and CUBLAS. Experiment results indicate that the proposed CRBM-based model obtains better forecasting accuracy for low-dimensional volatility and it also shows great potential in modeling for large-scale cases compared with traditional GARCH models. © 2012 Springer Science+Business Media New York.","Conditional restricted Boltzmann machine; Covariance matrix forecasting; GPU; High dimensional conditional covariance matrix; Neural network; Volatility forecasting","Conditional restricted boltzmann machines; Forecasting volatility; GPU; High-dimensional; Multicore architectures; Restricted boltzmann machine; Stochastic recurrent neural network; Volatility forecasting; Computer architecture; Computer software; Covariance matrix; Financial data processing; Neural networks; Recurrent neural networks; Stochastic models; Time series; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066486217&doi=10.1002%2fdac.3987&partnerID=40&md5=d02dd09dbe6500c17e643707d6789828","To forecast the future trend of financial activities through its rules, a convolutional neural network (CNN) is used to forecast stock index. Firstly, a CNN stock index prediction model is constructed, the structural parameter relationship of the CNN model is analyzed, and a CNN model algorithm is implemented. Secondly, the influence of model parameters on prediction results is discussed, and the stock index prediction model based on CNN-support vector machine (SVM) is established. At last, the empirical analysis is made, and the results show that the two prediction models are feasible and effective. It is concluded that the use of neural networks for financial prediction can deal with the continuous and categorical prediction variables and obtain good prediction results. © 2019 John Wiley & Sons, Ltd.","CNN; financial prediction; neural network; stock prediction","Convolution; Electronic trading; Financial markets; Neural networks; Support vector machines; Time series analysis; Convolution neural network; Convolutional neural network; Financial prediction; Financial time series; Stock index predictions; Stock predictions; Stock price forecasting; Structural parameter; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027469207&doi=10.1109%2fCCBD.2016.027&partnerID=40&md5=a67ab301d59ba5c3b7b50025c082a600","A novel financial time-series analysis method based on deep learning technique is proposed in this paper. In recent years, the explosive growth of deep learning researches have led to several successful applications in various artificial intelligence and multimedia fields, such as visual recognition, robot vision, and natural language processing. In this paper, we focus on the time-series data processing and prediction in financial markets. Traditional feature extraction approaches in intelligent trading decision support system are used to applying several technical indicators and expert rules to extract numerical features. The major contribution of this paper is to improve the algorithmic trading framework with the proposed planar feature representation methods and deep convolutional neural networks (CNN). The proposed system is implemented and benchmarked in the historical datasets of Taiwan Stock Index Futures. The experimental results show that the deep learning technique is effective in our trading simulation application, and may have greater potentialities to model the noisy financial data and complex social science problems. In the future, we expected that the proposed methods and deep learning framework could be applied to more innovative applications in the next financial technology (FinTech) generation. © 2016 IEEE.","convolutional neural networks; data visualization; Deep learning; machine learning; trend prediction","Artificial intelligence; Big data; Cloud computing; Commerce; Convolution; Data handling; Data visualization; Decision support systems; Deep learning; Deep neural networks; Finance; Financial data processing; Intelligent robots; Learning algorithms; Learning systems; Natural language processing systems; Network function virtualization; Neural networks; Time series analysis; Visual languages; Algorithmic trading; Convolutional neural network; Feature representation; Financial time series; Learning frameworks; Simulation applications; Technical indicator; Trend prediction; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039937089&doi=10.1109%2fISC2.2017.8090834&partnerID=40&md5=b7eb0c3e8525dce5df0c24fc645c9ad0","Stock market prediction has attracted a lot of attention from both business and academia. In this paper, we implement a model based on Recurrent Neural Networks (RNN) with Gated Recurrent Units (GRU) to predict the stock volatility in the Chinese stock market. We also propose many price related features which are used as inputs for our model. Apart from that, we carefully select official accounts from Chinese largest online social networks-Sina Weibo and extract the content posted by these accounts to analyze the public moods. An influence feature is derived based on the public moods to further improve the prediction model. The experimental results show that our model outperforms the baseline method and can achieve a good prediction performance. © 2017 IEEE.","Online Social Networks; Recurrent Neural Networks; Time Series Prediction","Commerce; Electronic trading; Finance; Financial markets; Forecasting; Recurrent neural networks; Smart city; Baseline methods; Chinese stock market; On-line social networks; Prediction model; Prediction performance; Recurrent neural network (RNN); Stock market prediction; Time series prediction; Social networking (online)"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054354418&doi=10.1109%2fICSSSM.2018.8464968&partnerID=40&md5=ee5f0b79628055726543e835ba28b213","It has always been a challenging issue for people to understand the stock market and make reasonable predictions. For a very long period, investors are trying to manually extract useful features from the financial market which generates an enormous volume of data every single day. People create a lot of technical indicators like MACD, TR, MFI to describe momentum, volume and volatility signals of the financial time series. However, the limitation is evident due to the efficiency of manually feature engineering. With the rapidly growing volume of data, deep neural network shows excellent performance in many research areas like natural language processing, voice recognition, image identification. It provides a new view to dig out potentially useful information automatically. In this paper, we present a novel end-to-end training using an embedding method to automatically extract features and get a summary representation of the daily market. Moreover, we apply the Long Short-Term Memory (LSTM) with attention mechanism to predict daily return ratio of HS300 index. The features extracted by the embedding layer show greater predictive power than manually defined technical signals by 92.42% lower MSE. Moreover, the use of attention mechanism also provides an average enhance of 55.68% in MSE. Our study shows that deep neuron network structure has a strong potential for better understanding market complex behaviors. © 2018 IEEE.","Embedding Method; LSTM; Market Prediction; Market Vector; Technical Indicator",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051531626&doi=10.1145%2f3205651.3205682&partnerID=40&md5=38ee7592b16b573853e0bd339fd22130","Stock market prediction plays an important role in financial decision-making for investors. Many of them rely on news disclosures to make their decisions in buying or selling stocks. However, accurate modelling of stock market trends via news disclosures is a challenging task, considering the complexity and ambiguity of natural languages used. Unlike previous work along this line of research, which typically applies bag-of-words to extract tens of thousands of features to build a prediction model, we propose a sentiment analysis-based approach for financial market prediction using news disclosures. Specifically, sentiment analysis is carried out in the pre-processing phase to extract sentiment-related features from financial news. Historical stock market data from the perspective of time series analysis is also included as an input feature. With the extracted features, we use a support vector machine (SVM) to build the prediction model, with its parameters optimised through particle swarm optimisation (PSO). Experimental results show that our proposed SVM and PSO-based model is able to obtain better results than a deep learning model in terms of time and accuracy. The results presented here are to date the best in the literature based on the financial news dataset tested. This excellent performance is attributed to the sentiment analysis done during the pre-processing stage, as it reduces the feature dimensions significantly. © 2018 Copyright held by the owner/author(s).","Financial market prediction; Particle swarm optimisation; Sentiment analysis; Support vector machine","Commerce; Data mining; Decision making; Deep learning; Financial markets; Forecasting; Information retrieval; Modeling languages; Particle swarm optimization (PSO); Sentiment analysis; Support vector machines; Time series analysis; Analysis-based approaches; Feature dimensions; Financial decisions; Machine learning approaches; Market prediction; Particle swarm optimisation; Pre-processing stages; Stock market prediction; Investments"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057319854&doi=10.1109%2fASONAM.2018.8508269&partnerID=40&md5=2412bb1d11dee3c145908afb240cfb95","With the advent of the artificial intelligence (AI) era, the combination of AI with financial technology (FinTech) has become a development trend in the financial industry. However, deep learning (DL) on the application of automated financial management has been rarely investigated. Thus, this research focuses on the applications of FinTech and DL in asset allocation and aims to optimize investment portfolio. The best investment portfolio in index-based funds based on Taiwan's index-type security investment trust funds are the main investment targets. Time series models for DL, that is, long short-term memory, predict the increase of each investment target and find the best investment portfolio in combination with the relevant asset allocation theory. In this research, we use the Markowitz mean-variance and Black-Litterman models as our asset allocation models for robo-advisor. Results show that the Black-Litterman model has a better accumulated return performance than the Morkowitz model and outperforms other strategies. The Human-Computer Interaction (HCI) dialogue service adopts artificial intelligence markup language (AIML) and a generative model. The main contribution of this paper is that we have developed an integrated knowledge-based and generative-based models for AI conversational robo-advisor. © 2018 IEEE.","Artificial Intelligence (AI); Conversational Commerce; Deep Learning; Financial Technology (FinTech); Robo-Advisor","Artificial intelligence; Deep learning; Human computer interaction; Knowledge based systems; Markup languages; Artificial intelligence mark up languages; Financial industry; Financial managements; Financial Technology (FinTech); Human Computer Interaction (HCI); Investment portfolio; Robo-Advisor; Security investments; Investments"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063442106&doi=10.1007%2f978-3-030-13463-1_1&partnerID=40&md5=d128a5762da5086dd933593e400267c7","Multivariate time series forecasting involves the learning of historical multivariate information in order to predict the future values of several quantities of interests, accounting for interdependencies among them. In finance, several of this quantities of interests (stock valuations, return, volatility) have been shown to be mutually influencing each other, making the prediction of such quantities a difficult task, especially while dealing with an high number of variables and multiple horizons in the future. Here we propose a machine learning based framework, the DFML, based on the Dynamic Factor Model, to first perform a dimensionality reduction and then perform a multiple step ahead forecasting of a reduced number of components. Finally, the components are transformed again into an high dimensional space, providing the desired forecast. Our results, comparing the DFML with several state of the art techniques from different domanins (PLS, RNN, LSTM, DFM), on both traditional stock markets and cryptocurrencies market and for different families of volatility proxies show that the DFML outperforms the concurrent methods, especially for longer horizons. We conclude by explaining how we wish to further improve the performances of the framework, both in terms of accuracy and computational efficiency. © Springer Nature Switzerland AG 2019.","Dynamic factor models; Multi-step ahead forecast; Multivariate time series forecasting; Volatility forecasting","Computational efficiency; Electronic money; Long short-term memory; Machine components; Machine learning; Time series; Dimensionality reduction; Dynamic factor modeling; Dynamic factor models; Machine learning approaches; Multi-step; Multivariate time series; State-of-the-art techniques; Volatility forecasting; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046646074&partnerID=40&md5=f35899208c4ae7d702b8cac615059496","In this paper we propose a new neural networks based regularization method requiring only 4 additional hyperparameter and that can be easily injected in any machine learning architecture. It is based on the use of auxiliary loss functions designed to appropriately learn data momenta. Our approach can be used both for classification and regression problems. A comparative analysis with real time series will be provided concerning cryptocurrency data, showing improvements in accuracy of about 5% with respect to existing approaches, without requiring additional training data or further parameters. The presented approach constitutes an innovative, new step towards the statistical moments oriented regularization scheme for statistical forecasting. © 2018, North Atlantic University Union. All rights reserved.","Cryptocurrency; Deep learning; Forecasting; Machine learning; Multitask learning; Neural networks","Artificial intelligence; Electronic money; Forecasting; Learning algorithms; Learning systems; Neural networks; Time series analysis; Comparative analysis; Financial forecasting; Multitask learning; Regression problem; Regularization methods; Regularization schemes; Statistical forecasting; Statistical moments; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998705847&partnerID=40&md5=f3fa06042299716f81a58ef587947ec2","We present an Artificial Neural Network (ANN) approach to predict stock market indices, particularly with respect to the forecast of their trend movements up or down. Exploiting different Neural Networks architectures, we provide numerical analysis of concrete financial time series. In particular, after a brief r´esum´e of the existing literature on the subject, we consider the Multi-layer Perceptron (MLP), the Convolutional Neural Networks (CNN), and the Long Short-Term Memory (LSTM) recurrent neural networks techniques. We focus on the importance of choosing the correct input features, along with their preprocessing, for the specific learning algorithm one wants to use. Eventually, we consider the S&P500 historical time series, predicting trend on the basis of data from the past days, and proposing a novel approach based on combination of wavelets and CNN, which outperforms the basic neural networks ones. We show, that neural networks are able to predict financial time series movements even trained only on plain time series data and propose more ways to improve results. © 2016, North Atlantic University Union. All rights reserved.","Artificial neural networks; Convolutional neural network; Deep Learning; Financial forecasting; Long shortterm memory; Multi-layer neural network; Recurrent neural network; Stock markets analysis; Time series analysis","Commerce; Convolution; Deep learning; Electronic trading; Financial markets; Forecasting; Learning algorithms; Long short-term memory; Memory architecture; Network layers; Neural networks; Recurrent neural networks; Time series analysis; Convolutional neural network; Convolutional Neural Networks (CNN); Financial forecasting; Financial time series; Multi layer perceptron; Neural networks architecture; Stock market index; Stock price prediction; Network architecture"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035056992&doi=10.18178%2fijmlc.2017.7.5.632&partnerID=40&md5=e1437833f03c6f5df40481ce9ac800e9","This paper is intended as a follow up to a previous study of ours - Financial Time Series Forecasting - A Machine Learning Approach. The aforementioned study evaluates traditional machine learning techniques for the task of financial time series forecasting. In this paper, we attempt to make use of the same base dataset, with the difference of making use of a novel branch of machine learning techniques known as Deep Learning. These techniques have been introduced with the objective of moving Machine Learning closer to one of its original goals: Artificial Intelligence. These deep architectures are known to excel in tasks such as image and text recognition, but have not been exploited as much in the field of finance. In particular, for this study we will be making use of Convolutional Neural Networks (CNNs) to forecast the next period price direction with respect to the current price. We achieve an accuracy of 65% when forecasting the next month price direction and 60% for the next week price direction forecast. Whilst these results are anything but random, we are not able to match or surpass results obtained by industry leading techniques such as Logistic Regression and Support Vector Machines.","Data science; Deep learning; Fintech; Machine learning; Stock market",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029623619&doi=10.1016%2fj.jocs.2017.08.018&partnerID=40&md5=5311234cd932b0c114e33e2798a435cb","Recurrent neural networks (RNNs) are types of artificial neural networks (ANNs) that are well suited to forecasting and sequence classification. They have been applied extensively to forecasting univariate financial time series, however their application to high frequency trading has not been previously considered. This paper solves a sequence classification problem in which a short sequence of observations of limit order book depths and market orders is used to predict a next event price-flip. The capability to adjust quotes according to this prediction reduces the likelihood of adverse price selection. Our results demonstrate the ability of the RNN to capture the non-linear relationship between the near-term price-flips and a spatio-temporal representation of the limit order book. The RNN compares favorably with other classifiers, including a linear Kalman filter, using S&P500 E-mini futures level II data over the month of August 2016. Further results assess the effect of retraining the RNN daily and the sensitivity of the performance to trade latency. © 2017 Elsevier B.V.","Futures markets; Limit order book; Recurrent neural networks","Classification (of information); Commerce; Correlation theory; Costs; Electronic trading; Financial data processing; Financial markets; Forecasting; Neural networks; Financial time series; High-frequency trading; Limit order book; Linear Kalman filters; Non-linear relationships; Recurrent neural network (RNNs); Sequence classification; Short sequences; Recurrent neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040316827&doi=10.1016%2fj.asoc.2017.12.022&partnerID=40&md5=acbbb05bbb8f237be40a490ffdc31019","Time series forecasting is one of the most effective ways to settle the elusive problems of increased penetration of energy industry and financial field. In recent years, neural networks are utilized in time series forecasting owing to the rationality and practicability. However, neural networks always overrate the performance of training data, which results in underestimating the test error. In this work, four important training tactics are proposed for the training and modeling of the networks, and the proposed model has a better forecasting result and a better extrapolation performance. The numerical simulation shows that the proposed methods have broader application in time series forecasting, it is not only effective for over-fitting problems but also has promoted the model accuracy considerably. © 2017 Elsevier B.V.","Artificial neural networks; Convolutional neural networks; Feature learning; Time series forecasting","Neural networks; Numerical methods; Rectifying circuits; Time series; Convolutional neural network; Energy industry; Feature learning; Over fitting problem; Perceptron neural networks; Research and application; Time series forecasting; Training tactics; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067881822&doi=10.1109%2fITNEC.2019.8729026&partnerID=40&md5=3475c0bef2942f7eda91baa4ee576277","Due to the extensive application of deep learning in processing time series and recent progress, LSTM (Long Short-Term Memory) neural network is the most commonly used and most powerful tool for time series models. The LSTM neural network is used to predict Apple stocks by using single feature input variables and multi-feature input variables to verify the prediction effect of the model on stock time series. The experimental results show that the model has a high accuracy of 0.033 for the multivariate input and is accurate, which is in line with the actual demand. For the univariate feature input, the predicted squared absolute error is 0.155, which is inferior to the multi-feature variable input. © 2019 IEEE.","LSTM; Multivariate feature input; RNN; Stock price; Univariate feature input","Costs; Deep learning; Electronic trading; Financial markets; Forecasting; Time series; Feature input; Forecasting stock prices; LSTM; Processing time; Recent progress; Stock price; Stock time series; Time series models; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065636375&doi=10.1109%2fPAAP.2018.00037&partnerID=40&md5=382c214b5d7adbeac4747b8ec72e8180","Time series forecasting has been regarded as a key research problem in various fields. such as financial forecasting, traffic flow forecasting, medical monitoring, intrusion detection, anomaly detection, and air quality forecasting etc. In this paper, we propose a sequence-to-sequence deep learning framework for multivariate time series forecasting, which addresses the dynamic, spatial-temporal and nonlinear characteristics of multivariate time series data by LSTM based encoder-decoder architecture. Through the air quality multivariate time series forecasting experiments, we show that the proposed model has better forecasting performance than classic shallow learning and baseline deep learning models. And the predicted PM2.5 value can be well matched with the ground truth value under single timestep and multi-timestep forward forecasting conditions. The experiment results show that our model is capable of dealing with multivariate time series forecasting with satisfied accuracy. © 2018 IEEE.","Encoder-decoder; LSTM; PM2.5; Sequence-to-sequence deep learning; Time series forecasting","Air quality; Anomaly detection; Decoding; Forecasting; Intrusion detection; Long short-term memory; Parallel architectures; Signal encoding; Time series; Encoder-decoder; Encoder-decoder architecture; LSTM; Multivariate time series; Nonlinear characteristics; PM2.5; Time series forecasting; Traffic flow forecasting; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955159878&doi=10.1080%2f13518470903037771&partnerID=40&md5=25f269cd44e8b39d33f4641ad455372f","The motivation for this paper is to investigate the use of alternative novel neural network (NN) architectures when applied to the task of forecasting and trading the euro/dollar (EUR/USD) exchange rate, using the European Central Bank (ECB) fixing series with only auto-regressive terms as inputs. This is done by benchmarking four different NN designs representing a higher-order neural network (HONN), a Psi Sigma Network and a recurrent neural network with the classic multilayer perception (MLP) and some traditional techniques,either statistical such as an auto-regressive moving average model,or technical such as a moving average convergence/divergence model, plus a naïve strategy. More specifically, the trading performance of all models is investigated in a forecast and trading simulation on the EUR/USD ECB fixing time series over the period 1999-2007 using the last one and half years for out-of-sample testing, an original feature of this paper. We use the EUR/USD daily fixing by the ECB as many financial institutions are ready to trade at this level and it is therefore possible to leave orders with a bank for business to be transacted on that basis. As it turns out, the MLP does remarkably well and outperforms all other models in a simple trading simulation exercise. However, when more sophisticated trading strategies using confirmation filters and leverage are applied, the HONN network produces better results and outperforms all other NN and traditional statistical models in terms of annualized return. © 2010 Taylor & Francis.","Confirmation filters; Higher-order neural networks; Leverage; Multi-layer perception networks; Psi Sigma networks; Quantitative trading strategies; Recurrent neural networks",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027707850&doi=10.1007%2f978-3-319-63309-1_70&partnerID=40&md5=eaecaf19adb0fe6414ef77c69e434d3a","We present a methodology for volatile time series forecasting using deep learning. We use a three-step methodology in order to remove trend and nonlinearities from data before applying two parallel deep neural networks to forecast two main features from processed data: absolute value and sign. The proposal is successfully applied to a volatile exchange rate time series problem. © Springer International Publishing AG 2017.",,"Computation theory; Finance; Forecasting; Intelligent computing; Time series; Absolute values; Exchange rate forecasting; Exchange rates; Time series forecasting; Deep neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039970639&doi=10.1016%2fj.ejor.2017.11.054&partnerID=40&md5=ac3b57da8599cac8f14f9a3588ba885d","Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading – they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk – also compared to the three benchmark models. © 2017 Elsevier B.V.","Deep learning; Finance; LSTM; Machine learning; Statistical arbitrage","Brain; Commerce; Costs; Decision trees; Deep learning; Deep neural networks; Electronic trading; Finance; Financial markets; Forecasting; Learning systems; Profitability; Regression analysis; Risk assessment; Classification methods; Directional movements; Financial time series predictions; Logistic regression classifier; LSTM; Market prediction; State-of-the-art techniques; Statistical arbitrage; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068690385&doi=10.1109%2fACCESS.2019.2923637&partnerID=40&md5=063127014f7880a9179a08356bd7f0c2","With the development of Internet lending, the use of peer-to-peer (P2P) as a new financial credit model has been increasing in China. However, this rapid development has led to a major potential risk. A few P2P enterprises operate well in the beginning but close within a short period because of the suspension of business, fraud, illegal fundraising, and blind expansion. Effective supervision of the P2P industry is an urgent problem. Trading volume reflects the operation stability of P2P platforms. Hence, predicting the volume of the P2P market is an important research topic. This paper first analyzes the trading data of a P2P platform. It is found that the sentiment of investor comments is related to the trading volume of the P2P platform. Then, we use the TextCNN model to classify the sentiment of investor comments and obtain the time series of changes in sentiment. It is verified that the time series of change in sentiment and the P2P volume index has statistical causality and a strong correlation. This paper proposes a model that uses the trend of change in investor sentiment to predict P2P trading volume. This model uses the historical time series change in investor sentiment, the P2P volume index, and WeekDay characteristics to predict future P2P trading volume. The experimental results show that the proposed model is better than a few existing baseline methods. Compared with baseline regression, the Pearson coefficient of the predicted and actual values of the proposed model is increased by 13.26%, the mean squared error is decreased by 27.62%, and the R-squared value is increased by 28.48%. © 2013 IEEE.","long short-term memory (LSTM); Peer-to-peer lending; sentiment tracking; trading prediction","Commerce; Crime; Forecasting; Investments; Long short-term memory; Mean square error; Time series; Baseline methods; Financial credits; Investor sentiments; Mean squared error; Operation stability; Pearson coefficient; Peer-to-peer lending; Strong correlation; Tellurium compounds"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049629999&partnerID=40&md5=a3c1ba4d0f298a8351732fa99aff9f28","Accurate prediction of exchange rates is critical for devising robust monetary policies. Machine learning methods such as shallow neural networks have higher predictive accuracy than time series models when trained on input features carefully crafted by domain knowledge experts. This suggests that deep neural networks, with their ability to learn abstract features from raw data, may provide improved predictive accuracy with raw exchange rates as inputs. The preponderance of research focuses on developed currency markets. The paucity of research in emerging currency markets, and the crucial role that stable currencies play in such economies, motivates us to investigate the effectiveness of deep networks for exchange rate prediction in emerging markets. Literature suggests that the Efficient Market Hypothesis, which posits that asset prices reflect all relevant information, may not hold in such markets because of extraneous factors such as political instability and governmental interventions. This motivates our hypothesis that inclusion of carefully chosen macroeconomic factors as input features may improve the predictive accuracy of deep networks in emerging currency markets. This position paper proposes novel input features based on currency clusters and presents our method for investigating the hypothesis using exchange rates from developed as well as emerging currency markets. © 2017 by SCITEPRESS - Science and Technology Publications, Lda.","Convolution Networks; Deep Learning; Emerging Markets; Exchange Rate Prediction; Neural Networks","Artificial intelligence; Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Neural networks; Accurate prediction; Efficient market hypothesis; Emerging markets; Exchange rates; Governmental intervention; Machine learning methods; Political instability; Predictive accuracy; Deep neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650716107&doi=10.1016%2fj.eswa.2010.09.037&partnerID=40&md5=7ec2e0d311716db7847a4deec9a167fd","This paper considers the prediction of noisy time series data, specifically, the prediction of financial signals. A novel Dynamic Ridge Polynomial Neural Network (DRPNN) for financial time series prediction is presented which combines the properties of both higher order and recurrent neural network. In an attempt to overcome the stability and convergence problems in the proposed DRPNN, the stability convergence of DRPNN is derived to ensure that the network posses a unique equilibrium state. In order to provide a more accurate comparative evaluation in terms of profit earning, empirical testing used in this work encompass not only on the more traditional criteria of NMSE, which concerned at how good the forecasts fit their target, but also on financial metrics where the objective is to use the networks predictions to generate profit. Extensive simulations for the prediction of one and five steps ahead of stationary and non-stationary time series were performed. The resulting forecast made by DRPNN shows substantial profits on financial historical signals when compared to various neural networks; the Pi-Sigma Neural Network, the Functional Link Neural Network, the feedforward Ridge Polynomial Neural Network, and the Multilayer Perceptron. Simulation results indicate that DRPNN in most cases demonstrated advantages in capturing chaotic movement in the financial signals with an improvement in the profit return and rapid convergence over other network models. © 2010 Elsevier Ltd. All rights reserved.","Dynamic Ridge Polynomial Neural Network; Financial signals; Higher order neural network; Time series prediction","Comparative evaluations; Empirical testing; Equilibrium state; Extensive simulations; Feed-Forward; Financial metrics; Financial signal; Financial time series predictions; Functional link neural network; Higher order; Higher order neural network; Multi layer perceptron; Network models; Non-stationary time series; Nonstationary; Polynomial neural networks; Profit earning; Rapid convergence; Simulation result; Stability and convergence; Time series prediction; Time-series data; Univariate; Feedforward neural networks; Finance; Financial data processing; Forecasting; Multilayer neural networks; Polynomials; Profitability; Recurrent neural networks; Time series; Computer simulation"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070385176&doi=10.1109%2fCTEMS.2018.8769290&partnerID=40&md5=43d67f8ddceae46d054a312aca6f7c59","Time series based model has been widely applied to estimate the future stock price, and aids investors' decisions and trades. However, due to high rate of volatility and non-linearity of time series, affecting stock market forecasting. To address this, artificial neural network (ANN) and deep neural network (DNN) have been applied in the area of stock price forecasting by various researchers. However, existing model use ANN and DNN with back propagation fails to provide flexible linear or nonlinear relationship among variables and they are difficult to train. The objective of this work is to present a modified back propagation neural network (MBNN) model that can handle huge density of nonlinear data, their relationship and give an optimal strategy for computationally hard problem. Experiments are conducted to evaluate performance of proposed MBNN over existing model in terms RMSE and MAPE. The outcome shows significant performance improvement by MBNN over state-of-art approach. © 2018 IEEE.","Artificial neural network; Data mining; Deep learning; machine learning; prediction system; time series","Backpropagation; Commerce; Data mining; Deep learning; Deep neural networks; Financial markets; Forecasting; Investments; Learning systems; Mechanics; Neural networks; Time series; Back propagation neural networks; Modified backpropagation; Non-linear relationships; Optimal strategies; Prediction systems; Stock forecasting; Stock market forecasting; Stock price forecasting; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069827868&doi=10.1016%2fj.eswa.2019.112842&partnerID=40&md5=c103c51089b93ec959b569f86ced47cf","This paper presents a recurrent neural network (RNN) which is improved by using an efficient discrete wavelet transform (DWT) for predicting a high-frequency time series. In the combined DWT-RNN model, first, a multiresolution based on B-spline wavelet of high order d (BSd) is used to decompose the time series into several smooth data sets. Therefore, an approximation data set (with low-frequency) and several detail data sets (with high-frequency), with small wave amplitude, are obtained. Then, all decomposed components are used as RNN inputs. The proposed BSd-RNN model can approximate smooth patterns with satisfactory accuracy, and because of the local properties, BSd is a better choice than other common DWT such as Haar and Daubechies of order n (dbn), for preprocessing the high-frequency time series. According to results of performance metrics for predicting four different stock indices, the BSd-RNN model outperforms other common DWT-RNN model such as Haar-RNN and dbn-RNN. Also, the results show the BSd-RNN model outperforms other common artificial neural network (ANN) model such as multilayer feed-forward neural network (FFNN). Finally, The results show that BS3-RNN predicting model has better predictive ability than other compared models which use other wavelets or other ANNs. © 2019","Artificial neural networks; B-spline wavelets multiresolution; Discrete wavelet transform; Financial time series forecasting; Return volatility","Discrete wavelet transforms; Financial data processing; Forecasting; Interpolation; Multilayer neural networks; Neural networks; Recurrent neural networks; Signal reconstruction; Time series; Artificial neural network models; Financial time series forecasting; High frequency time series; Multilayer feedforward neural networks; Multiresolution; Predictive abilities; Recurrent neural network (RNN); Return volatilities; Feedforward neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054221459&partnerID=40&md5=115bd9954bf454ebc09d726265f26496","The forecasting of time series is a common problem in different domains. Especially the financial sector that relies heavily on algorithmic trading, employs intelligent systems for this purpose. With technological advances in the domain of intelligent systems those forecasts tend to become more and more precise. However, using such black box methods often lacks the understanding, whether the underlying time series characteristics like stationarity or chaos are caught by the corresponding algorithm and what particular external factors like dataset size influence the outcome. In addition to that the knowledge base is lacking a systematic overview of available algorithms and their application on different time series. We aim to contribute to the knowledge base by (1) conducting a literature review and descriptive analysis revealing dependencies between characteristics and algorithm use and (2) evaluating the impact of influence factors like dataset size and prediction window on the performance of Deep Learning Systems (DLS) in the context of crude oil price prediction, considering two common tasks: a trend and an exact value prediction problem. © 2018 Association for Information Systems. All rights reserved.","Crude oil; Deep learning; Intelligent systems; Prediction; Time series","Crude oil; Deep learning; Information use; Intelligent systems; Knowledge based systems; Petroleum analysis; Time series; Algorithmic trading; Crude oil price prediction; Descriptive analysis; Financial sectors; Literature reviews; Technological advances; Time series characteristic; Time series prediction; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964875760&doi=10.1109%2fSYNASC.2015.49&partnerID=40&md5=64405d31be1f1ca282bed1d54d39812e","Forecasting has always been of interest. Whether one's field is finance, health or seismology, being able to predict future values based on previously gathered data proves to be invaluable when taking decisions concerning the future. In this paper, we research machine learning techniques for predictions on time series and choose the best models that fit our use case, Smart Farms, in which we distributedly analyze time series received from farm-monitoring sensors. On time series with short term dependencies, like temperature or pressure, we make predictions with Hidden Markov Models, whilst for those with long range dependencies, like ground wind speeds orprecipitations, we use Recurrent Neural Networks with Long Short-Term Memory architecture. © 2015 IEEE.","Hidden Markov Model; Long Short-Term Memory; Recurrent Neural Networks; Simultaneous Temporal and Contextual Splits","Artificial intelligence; Brain; Forecasting; Learning systems; Markov processes; Memory architecture; Recurrent neural networks; Time series; Trellis codes; Best model; Forecasting techniques; Long short term memory; Long-range dependencies; Machine learning techniques; Monitoring sensors; Sensor data; Simultaneous Temporal and Contextual Splits; Hidden Markov models"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062770567&doi=10.1109%2fSSCI.2018.8628641&partnerID=40&md5=fdc0a42330e81f4f3be46ec78b64d595","In this paper, we propose a novel stock price prediction model based on deep learning. With the success of deep learning algorithms in the field of Artificial Neural Network (ANN), we choose to solve the regression based problems (stock price prediction in our case). Stock price prediction is a challenging problem due to its random movement. This hybrid model is a combination of two well-known networks, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU). We choose the SP 500 historical time series data and use significant evaluation metrics such as mean squared error, mean absolute percentage error etc., that conventional approaches have used. In experiment section, we have described the effectiveness of each of the component of our model along with its performance gain over the state-of-the-art approach. Our prediction model provides less error by considering this random nature (change) for a large scale of data. © 2018 IEEE.","DNN; GRU; Hybrid-network; LSTM; Stock price prediction","Electronic trading; Errors; Financial markets; Forecasting; Learning algorithms; Long short-term memory; Mean square error; Conventional approach; Evaluation metrics; Hybrid network; LSTM; Mean absolute percentage error; Mean squared error; State-of-the-art approach; Stock price prediction; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751613501&doi=10.1016%2fj.asoc.2010.09.007&partnerID=40&md5=7b7e2c9c766a3699b04ade7640a7992c","This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits. © 2010 Published by Elsevier B.V. All rights reserved.","Artificial bee colony algorithm (ABC); Recurrent neural network (RNN); Stepwise regression-correlation selection (SRCS); Wavelet transform","Artificial bee colonies; Dow Jones Industrial averages; Haar wavelets; Input features; Integrated systems; International stock markets; Parameter spaces; Real-time trading; Simulation result; Stepwise regression; Stock exchange; Stock indices; Stock market; Stock price; Stock price forecasting; Technical indicator; Three stages; Algorithms; Commerce; Feature extraction; Finance; Forecasting; Integrated control; Integrated optics; Optimization; Profitability; Recurrent neural networks; Regression analysis; Reinforcement learning; Time series; Wavelet transforms"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065043935&doi=10.1007%2f978-3-030-16142-2_42&partnerID=40&md5=2334a38b8ef44259449630bbc4b4d5a9","Multivariate time-series early classification is an emerging topic in data mining fields with wide applications like biomedicine, finance, manufacturing, etc. Despite of some recent studies on this topic that delivered promising developments, few relevant works can provide good interpretability. In this work, we consider simultaneously the important issues of model performance, earliness, and interpretability to propose a deep-learning framework based on the attention mechanism for multivariate time-series early classification. In the proposed model, we used a deep-learning method to extract the features among multiple variables and capture the temporal relation that exists in multivariate time-series data. Additionally, the proposed method uses the attention mechanism to identify the critical segments related to model performance, providing a base to facilitate the better understanding of the model for further decision making. We conducted experiments on three real datasets and compared with several alternatives. While the proposed method can achieve comparable performance results and earliness compared to other alternatives, more importantly, it can provide interpretability by highlighting the important parts of the original data, rendering it easier for users to understand how the prediction is induced from the data. © Springer Nature Switzerland AG 2019.","Attention; Deep neural network; Early classification on time-series","Decision making; Deep neural networks; Time series; Attention; Attention mechanisms; Critical segments; Learning frameworks; Learning methods; Model performance; Multivariate time series; Temporal relation; Data mining"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062878628&doi=10.1109%2fDSAA.2018.00019&partnerID=40&md5=a25e4feb317842406639a984e19658b5","Early classification on multivariate time series is an important research topic in data mining with wide applications to various domains like medical diagnosis, motion detection and financial prediction, etc. Shapelet is probably one of the most commonly used approaches to tackle early classification problem, but one drawback of shaplet is its inefficiency. More importantly, the extracted shapelets may not be applicable to every test case at any time point. This work focuses on early classification of multivariate time series and proposes a novel framework named Multi-Domain Deep Neural Network (MDDNN), in which convolutional neural network (CNN) and long-short term memory (LSTM) are incorporated to learn feature representation and relationship embedding in the long sequences with long time lags. The proposed model can make predictions at any time point of a multivariate time series with the help of a truncation process. We conducted experiments on four real datasets and compared with state-of-the-art algorithms. The experimental results indicate that the proposed method outperforms the alternatives significantly on both of earliness and accuracy. Detailed analysis about the proposed model is also provided in this work. To the best of our knowledge, this is the first work that incorporates deep neural network methods (CNN and LSTM) and multi-domain approach to boost the problem of early classification on multivariate time series. © 2018 IEEE.","Convolutional Neural Networks; Early Classification; LSTM; Multi-domain Inputs; Time Series Analysis","Advanced Analytics; Computer aided diagnosis; Convolution; Data mining; Deep neural networks; Long short-term memory; Medical computing; Convolutional neural network; Feature representation; LSTM; Multi domains; Multivariate time series; Neural network method; Relationship embedding; State-of-the-art algorithms; Time series analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962094403&doi=10.1016%2fj.neucom.2015.01.109&partnerID=40&md5=2da11b27609f37a65d53ea2711eb77e0","This paper presents a novel type of recurrent neural network, the regularized dynamic self-organized neural network inspired by the immune algorithm. The regularization technique is used with the dynamic self-organized multilayer perceptrons network that is inspired by the immune algorithm. The regularization has been addressed to improve the generalization and to solve the over-fitting problem. In this work, the average values of 30 simulations generated from 10 financial time series are examined. The results of the proposed network were compared with the standard dynamic self-organized multilayer perceptrons network inspired by the immune algorithm, the regularized multilayer neural networks and the regularized self-organized neural network inspired by the immune algorithm. The simulation results indicated that the proposed network showed average improvement using the annualized return for all signals of 0.491, 8.1899 and 1.0072 in comparison to the benchmarked networks, respectively. © 2015 Elsevier B.V.","Dynamic neural network; Exchange rate time series; Financial time series prediction","Algorithms; Cybernetics; Finance; Financial data processing; Multilayers; Neural networks; Recurrent neural networks; Time series; Dynamic neural networks; Exchange rates; Financial time series; Financial time series predictions; Immune algorithms; Over fitting problem; Regularization technique; Self-organized neural networks; Multilayer neural networks; algorithm; Article; artificial neural network; controlled study; dynamic self-organized neural network; financial information system; financial time series prediction; intermethod comparison; mathematical parameters; prediction; priority journal; quality control; regularized multilayer neural network; regularized self-organized neural network; signal noise ratio; simulation"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958527313&doi=10.1007%2f978-3-319-11298-5_16&partnerID=40&md5=c051f90ee958b7087f5af56f3dc36172","Time series analysis is a fundamental subject that has been addressed widely in different fields. It has been exploited and used in different scientific fields for example, natural, biomedical, economic and industrial data as well as financial time series. In this paper, we consider the application of a novel neural network architecture inspired by the immune algorithm and the recurrent links for the prediction of Lorenz and earthquake time series by exploiting the inherent temporal capabilities of the recurrent neural model. The performance of this network is benchmarked against ""traditional"", rate-encoded, neural networks; a Multi-Layer Perceptron network, a Jordan and an Elman neural network as well as the self organized neural network inspired by the immune algorithm. The results indicate that the inherent temporal characteristics of the recurrent links network make it extremely well suited to the processing of time series based data. © 2014 Springer International Publishing Switzerland.","and physical time series prediction; Recurrent neural network; self organised neural network","Algorithms; Financial data processing; Intelligent systems; Network architecture; Recurrent neural networks; Time series analysis; Dynamic neural networks; Elman neural network; Financial time series; Multi-layer perceptron networks; Physical time; Self-organised; Self-organized neural networks; Temporal characteristics; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062622552&doi=10.1109%2fBigData.2018.8622303&partnerID=40&md5=ea981bbf9fefb64b711a779d7e53db33","Illegal insider trading of stocks is based on releasing non-public information (e.g., new product launch, quarterly financial report, acquisition or merger plan) before the information is made public. Detecting illegal insider trading is difficult due to the complex, nonlinear, and non-stationary nature of the stock market. In this work, we present an approach that detects and predicts illegal insider trading proactively from large heterogeneous sources of structured and unstructured data using a deep-learning based approach combined with discrete signal processing on the time series data. In addition, we use a tree-based approach that visualizes events and actions to aid analysts in their understanding of large amounts of unstructured data. Using existing data, we have discovered that our approach has a good success rate in detecting illegal insider trading patterns. © 2018 IEEE.","Illegal Insider Trading;; Natural Language Processing; Neural Network; Stock Market; Time Series Prediction","Big data; Commerce; Crime; Deep learning; Financial markets; Learning algorithms; Natural language processing systems; Neural networks; Signal processing; Time series; Trees (mathematics); Heterogeneous sources; Insider trading; Learning-based approach; NAtural language processing; Pro-active approach; Public information; Time series prediction; Tree-based approach; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048045372&doi=10.23919%2fICITST.2017.8356346&partnerID=40&md5=20ca0e1bd5e8068d3cf17a79e00ab525","The advent of Data Science has led to data being evermore useful for an increasing number of organizations who want to extract knowledge from it for financial and research purposes. This has triggered data to be mined at an even faster pace causing the rise of Data Centers that host over thousands of machines together with thousands of jobs running in each of those machines. The growing complexities associated with managing such a huge infrastructure has caused the scheduling management systems to be inefficient at resource allocation across these machines. Hence, resource usage forecasting of machines in data centers is a growing area for research. This study focuses on the Time Series forecasting of CPU usage of machines in data centers using Long Short-Term Memory (LSTM) Network and evaluating it against the widely used and traditional autoregressive integrated moving average (ARIMA) models for forecasting. The final LSTM model had a forecasting error in the range of 17-23% compared to ARIMA model's 3742%. The results clearly show that LSTM models performed more consistently due to their ability to learn non-linear data much better than ARIMA models. © 2017 Infonomics Society.","ARIMA Model; CPU Usage forecasting; Data Center; LSTM Network","Forecasting; Scheduling; ARIMA modeling; Autoregressive integrated moving average models; Data centers; Forecasting error; Research purpose; Resource usage; Scheduling management system; Time series forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058350678&doi=10.1016%2fj.procs.2018.10.340&partnerID=40&md5=752965ef13b627d93b0828fd21b9baf2","Stock price time series are extremely nonlinear in nature and hence, accurate stock price forecasting has been a challenge. Accurate prediction of stock prices and the direction of stock price movement is also essential for a stock trader/investor in order to trade profitably. A deep learning approach to stock price forecasting is presented in this study. A total of fourteen different deep learning models based on Long-Short Term Memory (LSTM), Gated Recurring Unit (GRU), Convolutional Neural Networks (CNN) and Extreme Learning Machines (ELM) are designed and empirically evaluated on all stocks in the S&P BSE-BANKEX index for their ability to generate one-step ahead and four-step ahead forecasts. Performance of the proposed systems is evaluated in terms of the Root Mean Squared Error (RMSE), Directional Accuracy (DA) and the Median Absolute Percentage Error (MdAPE). Results indicate that deep learning models proposed in this study are capable of generating highly accurate stock price forecasts. © 2018 The Authors. Published by Elsevier B.V.","CNN; Deep learning; ELM; Financial time-series; GRU; LSTM","Commerce; Electronic trading; Financial markets; Forecasting; Long short-term memory; Mean square error; Time series; Convolutional Neural Networks (CNN); Extreme learning machine; Financial time series; LSTM; Root mean squared errors; Stock price forecasting; Stock price forecasts; Stock price movements; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056490365&doi=10.1109%2fIJCNN.2018.8489360&partnerID=40&md5=73208f0dd2689c862f4c839386efe2e0","Over recent decades, globalization has resulted in a steady increase in cross-border financial flows around the world. To build an abstract representation of a real-world financial market situation, we structure the fundamental influences among homogeneous and heterogeneous markets with three types of correlations: The inner-domain correlation between homogeneous markets in various countries, the cross-domain correlation between heterogeneous markets, and the time-series correlation between current and past markets. Such types of correlations in global finance challenge traditional machine learning approaches due to model complexity and nonlinearity. In this paper, we propose a novel cross-domain deep learning approach (Cd-DLA) to learn real-world complex correlations for multiple financial market prediction. Based on recurrent neural networks, which capture the time-series interactions in financial data, our model utilizes the attention mechanism to analyze the inner-domain and cross-domain correlations, and then aggregates all of them for financial forecasting. Experiment results on ten-year financial data on currency and stock markets from three countries prove the performance of our approach over other baselines. © 2018 IEEE.","attention neural network; deep learning; financial analysis","Commerce; Complex networks; Electronic trading; Financial markets; Forecasting; Recurrent neural networks; Time series; Abstract representation; Attention mechanisms; Complex correlation; Financial analysis; Financial forecasting; Heterogeneous markets; Machine learning approaches; Market prediction; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002813412&doi=10.1002%2fisaf.1401&partnerID=40&md5=9e709b9a8f80b8137536e8f544ac57ab","The scope of this manuscript is to present a new short-term financial forecasting and trading tool: the Gene Expression Programming (GEP) Trader Tool. It is based on the gene expression programming algorithm. This algorithm is based on a genetic programming approach, and provides supreme statistical and trading performance when used for modelling and trading financial time series. The GEP Trader Tool is offered through a user-friendly standalone Java interface. This paper applies the GEP Trader Tool to the task of forecasting and trading the future contracts of FTSE100, DAX30 and SandP500 daily closing prices from 2000 to 2015. It is the first time that gene expression programming has been used in such massive datasets. The model’s performance is benchmarked against linear and nonlinear models such as random walk model, a movingaverage convergence divergence model, an autoregressive moving average model, a genetic programming algorithm, a multilayer perceptron neural network, a recurrent neural network a higher order neural network. To gauge the accuracy of all models, both statistical and trading performances are measured. Experimental results indicate that the proposed approach outperforms all the others in the in-sample and out-of-sample periods by producing superior empirical results. Furthermore, the trading performances are improved further when trading strategies are imposed on each of the models. © 2016 John Wiley and Sons, Ltd.","Gene expression; Genetic algorithm; Trading; Transaction",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065601062&doi=10.1109%2fAICAI.2019.8701258&partnerID=40&md5=836d28838447606093d59d292d5a863a","The variation and dependency on different parameters of stock market makes prediction a complex process. Artificial neural Networks have been proven to be useful in such cases to predict the stock values. The parameters involved and the commonly used algorithms are discussed and compared in this paper. In case of backpropagation algorithm, a feed forward network is present and weights are modified by back propagating the error. Similarly, significant modification is introduced in Sup-port Vector Machines Algorithm(SVMA) which results in higher accuracy rates. Presence of kernel and other parameters make it more flexible. Long Short-Term Memory(LSTM), another commonly used time series forecasting algorithm, is a special type of Recurrent Neural Network(RNN) that uses gradient descent algorithm. This paper provides a comparative analysis between these algorithms on the basis of accuracy, variation and time required for different number of epochs. The T-test hypothesis test was used for further analysis to test the reliability of each algorithm. © 2019 IEEE.","Artificial Neural Network(ANN); Back-propgation; Long Short-Term Memory(LSTM); Recurrent Neural Netwrok(RNN); Support Vector Machines(SVM); T-tests","Backpropagation algorithms; Brain; Commerce; Electronic trading; Financial markets; Forecasting; Neural networks; Reliability analysis; Support vector machines; Back-propgation; Feed-forward network; Gradient descent algorithms; Predictive algorithms; Recurrent neural network (RNN); Recurrent Neural Netwrok(RNN); T-tests; Time series forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050027999&doi=10.1109%2fISS1.2017.8389302&partnerID=40&md5=752a5b6c4d8a3ce8b07e99860c22f457","In this paper, a survey on the efficacy of neural network models in predicting market trends is performed by presenting a detailed taxonomy of a few recently proposed models. After surveying the results presented, it is demonstrated that neural networks can be superior when applied to trading simulation, and have greater potential to model noisy financial data compared to traditional classifier approaches. © 2017 IEEE.","Deep Learning; Financial Time Series; Machine Learning; Neural Networks; Trend Analysis","Commerce; Deep learning; Financial data processing; Learning systems; Neural networks; Surveys; Financial data; Financial time series; Market trends; Neural network model; Neural network techniques; Trend analysis; Time series analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039923580&doi=10.15439%2f2017F449&partnerID=40&md5=5a321a8a091cedb80c2190816a635a7e","The paper presents aspects related to developing methods for financial time series forecasting using deep learning in relation to multi-agent stock trading system, called A-Trader. On the basis of this model, an investment strategies in A-Trader system can be build. The first part of the paper briefly discusses a problem of financial time series on FOREX market. Classical neural networks and deep learning models are outlined, their performances are analyzed. The final part presents deployment and evaluation of a deep learning model implemented using H20 library as an agent of A-Trader system. © 2017 PTI.",,"Commerce; Deep learning; Finance; Financial data processing; Information systems; Multi agent systems; Time series; Water; Classical neural networks; Financial time series; Financial time series forecasting; Forex markets; Investment strategy; Learning models; Multi agent; Stock trading system; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067436089&doi=10.1109%2fICIT.2018.00046&partnerID=40&md5=f25cef2ce8ff0f7f2d7777fe615bda57","Predicting stock market is not an easy task as it is a chaotic system i.e. whose dynamics are sensitive to arbitrarily small differences in initial conditions. Any small changes in the system can produce compound errors in predicting the future behavior of the system. Over the last few years, many machine learning algorithms have been used in an attempt to forecast stock prices. This paper evaluates the effectiveness of a type of Recurrent Neural Network known as Long Short Term Memory (LSTM) to implement technical analysis for making predictions about stock prices of AAPL ticker from NASDAQ exchange. Performance with three popular output activation layers is tested with Adam optimizer as back-propagation algorithm. The performance is compared using Root Mean Square Deviation. The model had an average RMSE value of 12.483 with linear output activation scaled to range (0,1) and 3.258 for the same scaled to a range of (-1,1), 21.769 with sigmoid output activation scaled to range (0,1) and 21.738 with tanh output activation scaled to a range of (-1,1). © 2018 IEEE.","Adam Optimizer; Long short term memory; Recurrent neural networks; Stock market prediction; Technical Analysis; Time series analysis","Backpropagation algorithms; Brain; Chaotic systems; Chemical activation; Commerce; Costs; Electronic trading; Financial markets; Forecasting; Learning algorithms; Machine learning; Recurrent neural networks; Time series analysis; Activation layer; Initial conditions; Nasdaq Exchange; Optimizers; Root mean square deviations; Short-term forecasting; Stock market prediction; Technical analysis; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066271331&doi=10.1016%2fj.eswa.2019.05.020&partnerID=40&md5=e0212fdaa6eb4f7777440b61e945eb81","Credit products are a crucial part of business of banks and other financial institutions. A novel approach based on time series of customer's data representation for predicting willingness to take a personal loan is shown. Proposed testing procedure based on moving window allows detection of complex, sequential, time based dependencies between particular transactions. Moreover, this approach reduces noise by eliminating irrelevant dependencies that would occur due to the lack of time dimension analysis. The system for identifying customers interested in credit products, based on classification with random forests and deep neural networks is proposed. The promising results of empirical studies prove that the system is able to extract significant patterns from customers historical transfer and transactional data and predict credit purchase likelihood. Our approach, including the testing method, is not limited to banking sector and can be easily transferred and implemented as a general purpose direct marketing campaign system. © 2019 Elsevier Ltd","Boruta algorithm; Consumer credit; Data mining; Database marketing; Deep belief networks; Deep learning; Direct marketing; Feature selection; Marketing campaigns; Random forest; Retail banking; Time series","Commerce; Decision trees; Deep learning; Deep neural networks; Feature extraction; Sales; Testing; Time series; Consumer credits; Database marketing; Deep belief networks; Direct marketing; Marketing campaign; Random forests; Retail banking; Data mining"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061796761&doi=10.1109%2fBDCAT.2018.00027&partnerID=40&md5=1f323dd13e4d4d0eb2827061d4c08c90","Stock price movement is typically affected by a lot of hidden factors. Predicting stock price direction, especially short-term direction, is very challenging and consistently attracts researches. Deep recurrent neural networks, such as Long Short-Term Memory, typically outperform statistical time series models and traditional machine learning approaches with their mechanisms of learning to vectorize historical information. However, encoding entire history into a vector may unavoidably causes information loss regardless of memory learning and updating mechanisms, especially for those tasks where decisions need to be made on the current time point and similar historical time points are of great references to the decision making. In this paper, we propose a new deep architecture called Recurrent Embedding Kernel (REK) that can learn to make optimal decisions by referring to the entire history instead of just current memory vectors. Experimental results on multiple stock ETFs with different long-term trends show that REK outperforms RNN, LSTM, and GRU, on predicting daily price direction. © 2018 IEEE.","deep learning; recurrent architecture; recurrent embedding kernel; stock prediction; time series","Big data; Decision making; Deep learning; Embeddings; Financial markets; Forecasting; Memory architecture; Network architecture; Time series; Deep architectures; Historical information; Machine learning approaches; Optimal decisions; recurrent embedding kernel; Stock predictions; Stock price movements; Time series models; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068864101&doi=10.1007%2fs40815-019-00688-w&partnerID=40&md5=8f5f8ccb9b79884eb302469df9eb3eba","In this paper, the author proposes an innovative Chaotic Interval Type-2 Fuzzy Neuro-oscillatory Network (CIT2-FNON) for worldwide financial prediction. Inspired by the author’s original work on Lee-oscillator—a chaotic discrete-time neural oscillator with profound transient-chaotic property, CIT2-FNON provides: (1) effective modeling of Interval Type-2 Fuzzy Logic with Chaotic Transient-Fuzzy Membership Function (CTFMF); and (2) time-series recurrent neural network training and prediction with Chaotic Bifurcation Transfer Function (CBTF). Different from the contemporary research on Type-2 Fuzzy Logic Systems (T2FLS) which mainly focus on the R&D of the Interval Type-2 Fuzzy Logic (IT2FL)—a simplified version of T2FLS due to its computational complexity, the main innovation of this paper include: (1) the Chaotic Type-2 Transient-Fuzzy Logic (CT2TFL) proposed in this paper provides a truly T2FLS with remarkable chaotic transient-fuzzy property to resolve the computational complexity problem; and (2) different from contemporary fuzzy-neuro systems which focus on the integration of fuzzy logic and neural networks as separated functional modules, the CIT2-FNON introduced in this paper is constructed by Lee-oscillators which serves as “transient-fuzzy input neurons” of the recurrent network and effectively converts it into CT2TFL system. In other words, the chaotic transient-fuzzification process is actually part of the neural model of the CIT2-FNON. From the implementation perspective, CIT2-FNON is integrated with 2048-trading day time-series financial data and Top-10 major financial signals as financial fuzzy signals (FFS) for the real-time prediction of 129 worldwide financial products. © 2019, Taiwan Fuzzy Systems Association.","Chaotic bifurcation transfer function; Chaotic neural oscillatory network; Chaotic transient-fuzzy membership function; Financial prediction; Interval type-2 fuzzy logic; Lee-oscillator","Bifurcation (mathematics); Complex networks; Computational complexity; Computer circuits; Finance; Forecasting; Fuzzy inference; Fuzzy neural networks; Membership functions; Recurrent neural networks; Time series; Transfer functions; Chaotic bifurcation; Financial prediction; Fuzzy membership function; Interval type-2 fuzzy logic; Oscillatory networks; Fuzzy logic"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053528190&doi=10.1007%2fs11227-018-2577-1&partnerID=40&md5=9e7f2087b7dd99337521b598978e1787","This paper aims at developing a new method by which to build a data-driven portfolio featuring a target risk–return. We first present a comparative study of recurrent neural network models (RNNs), including a simple RNN, long short-term memory (LSTM), and gated recurrent unit. The models are applied to the investment universe consisted of 10 stocks in the S& P500. The experimental results show that the LSTM-based prediction model outperforms the others in terms of hit ratio of 1-month-ahead forecasts. We then build predictive threshold-based portfolios (TBPs) that are subsets of the universe satisfying given threshold criteria for the LSTM-based return forecasts. The TBPs are rebalanced monthly to restore equal weight to the constituents of the TBPs. We find that the risk and return profile of the realized TBP represents a monotonically increasing frontier on the risk–return plane, where the equally weighted universe portfolio plays a role in the lower bound of TBPs. This shows the availability of TBPs in targeting specific risk–return levels, and the EWP of an universe plays a role in the reference portfolio of the TBPs. In the process, thresholds play dominant roles in characterizing risk, return, and the prediction accuracy of the TBPs. The TBP is more data-driven in designing portfolio return and risk than existing ones, in the sense that it requires no prior knowledge of finance such as financial assumptions, financial mathematics, or expert insights. For practical uses, we present a multiperiod TBP management method and also discuss the application of TBP to mean–variance portfolios to reduce estimation risk. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Efficient frontier; Financial time series; Portfolio management; Recurrent neural networks","Financial data processing; Financial markets; Forecasting; Investments; Recurrent neural networks; Risk perception; Comparative studies; Efficient frontier; Financial mathematics; Financial time series; Management method; Portfolio managements; Prediction accuracy; Recurrent neural network model; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028594302&doi=10.1109%2fICSSSM.2017.7996306&partnerID=40&md5=99179627230cde5a49e9d3dfd45cc154","Stock market prediction has attracted much attention from academia as well as business. However, it is a challenging research topic, in which many advanced computational methods have been proposed, but not yet attained a desirable and reliable performance. This study proposes a new method for stock market prediction, which adopts the Long Short-Term Memory (LSTM) neural network and incorporates investor sentiment and market factors to improve forecasting performance. By extracting investor sentiment from forum posts using Naïve Bayes, this paper makes it possible to analyze the irrational component of stock price. Our empirical study on CSI300 index proves that our prediction method provides better prediction performance. It gives a prediction accuracy of 87.86%, outperforming other benchmark models by at least 6%. Furthermore, our empirical study reveals evidence that helps to better understand investor sentiment and stock behaviors. Finally, this work shows the potential of deep learning financial time series in the presence of strong noises. © 2017 IEEE.","Deep learning; Investor sentiment; Stock market prediction","Commerce; Deep learning; Finance; Financial data processing; Financial markets; Forecasting; Long short-term memory; Financial time series; Forecasting performance; Investor sentiments; Prediction accuracy; Prediction methods; Prediction performance; Reliable performance; Stock market prediction; Investments"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045276426&doi=10.1109%2fICASID.2017.8285747&partnerID=40&md5=734f8077406f853b615a400cf66eb831","Trend forecasting is considered a difficult task, especially for China stock market due to its highly uncertainty. The study compares six forecasting models, i.e., Support Vector Machine (SVM), Naive Bayes, Decision Tree, Multilayer perceptron (MLP), Recurrent neural network (RNN), and Long Short-Term Memory (LSTM). 9 features combinations are selected based on 23 technical indicators which are commonly used in stock market analysis, and trainsets of 12 different records numbers are chosen to compare the performance of the models under different scenarios. Evaluation is carried out on 8 years of historical data from 2008 to 2015 of the listed company (000592) in China stock market. Experimental results show that the performance of deep learning models MLP, RNN, LSTM is better than other models with respect to the index of accuracy. MLP is 20.75% higher than Decision Tree, Decision Tree is better than others under f-measure, and Decision Tree is 40.02% higher than Naive Bayes. Experimental results also show that in the imbalanced stock market data, the performance of models RNN and Decision Tree is better than others. © 2017 IEEE.","Deep learning; Stock market; Trend forecasting","Classifiers; Commerce; Decision trees; Deep learning; Financial markets; Forecasting; Mobile devices; Support vector machines; Trees (mathematics); China stock markets; Comparative studies; Forecasting models; Multi layer perceptron; Recurrent neural network (RNN); Stock market analysis; Technical indicator; Trend forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069440052&partnerID=40&md5=3ddb022f37168a348e54458dd8a1b5e1","In this study, we consider the relationship between oil and gas prices, the Dow Jones index, the US dollar index and their volatility indicators. Application of wavelet analysis allows to reveal regularities of dynamics of selected time series at different periods. The Wavelet approach makes it possible to determine how these variables interact at different frequencies, and how this interaction evolves over time on different frequency scales. Common revenue movements of the studied time series characterize the behavior of the relevant markets. The levels of high volatility at similar intervals explain that there is a link between the changes in these markets, and the global economy is vulnerable to oil and gas prices, the value of the dollar index and the Dow Jones index. At the next stage of the research, a comparison of the predictive capabilities of Long Short Term Memory and Wavelet based Back Propagation neural networks for co-movement leaders is made. © 2019 CEUR-WS. All rights reserved.","Neural networks; Volatility; Wavelet analysis; Wavelet coherence; Wavelet multiple correlation and cross correlation","Backpropagation; Commerce; Costs; Financial markets; Industrial research; Knowledge management; Neural networks; Time series; Time series analysis; Wavelet analysis; Back propagation neural networks; Cross correlations; Different frequency; Oil and gas prices; Predictive capabilities; Us dollar indices; Volatility; Wavelet coherences; Motion estimation"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018755109&doi=10.1007%2fs11063-017-9629-z&partnerID=40&md5=0ea1255d2dd983c984cbfc535647c7f4","In this paper, we introduce a model based on Convolutional Neural Network for forecasting foreign exchange rates. Additionally, a method of transforming exchange rates data from 1D structure to 2D structure is proposed. The transaction of the foreign exchange market has periodic characteristics, however, due to the technical limitations, these characteristics cannot be utilized by existing time series forecasting models. In this paper, we propose a model which can process 2D structure exchange rates data and put these characteristics to good use. Exchange rates Euro against US dollar, US dollar against Japanese yen and British Pound Sterling against US dollar are researched in this paper. Our experimental results show that, when compared with Artificial Neural Network, Support Vector Regression and Gated Recurrent Unit, the proposed model can effectively improve the accuracy of long-term forecasting. © 2017, Springer Science+Business Media New York.","Adaptive gradient algorithm; Convolutional neural network; Foreign exchange rates forecasting; Long-term forecasting","Convolution; Finance; Forecasting; Metadata; Neural networks; Convolutional neural network; Foreign exchange rates; Gradient algorithm; Long-term forecasting; Model-based OPC; Support vector regression (SVR); Technical limitations; Time series forecasting models; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062693213&doi=10.1109%2fACCESS.2019.2900371&partnerID=40&md5=3fd01033ab34e1ca1f5ec93216fc950d","Multivariate time series forecasting recently has received extensive attention with its wide application in finance, transportation, environment, and so on. However, few of the currently developed models have considered the impact of noise on prediction. Since multivariate time series contains multiple subsequences with strong nonlinear fluctuations, it is also difficult to obtain satisfactory prediction results. In this paper, aiming at improving prediction performance, we have proposed a novel ensemble three-phase model called adaptive noise reducer-stacked auto-encoder-validating-AdaBoost-based long short-term memory (ANR-SAE-VALSTM). We start with an introduction of a novel ANR for time series noise elimination. The SAEs are then used to extract features from the de-noised multivariate time series. Finally, we feed the de-noised features into the VALSTM to train an ensemble over-fitting prevention predictor. The proposed model is employed on the Beijing PM2.5 dataset and GEFCom2014 Electricity Price dataset. Compared with other popular models, the proposed model has achieved the best prediction performance in all prediction horizons. In addition, a careful ablation study is conducted to demonstrate the efficiency of our model design. © 2013 IEEE.","adaptive noise reducer; long short-term memory; Multivariate time series forecasting; stacked auto-encoders; validating AdaBoost algorithm","Adaptive boosting; Brain; Forecasting; Learning systems; Signal encoding; Spurious signal noise; Time series; AdaBoost algorithm; Adaptive noise; Auto encoders; Electricity prices; Multivariate time series; Prediction horizon; Prediction performance; Satisfactory predictions; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057856973&doi=10.1016%2fj.knosys.2018.10.034&partnerID=40&md5=b73efaf564b39e115a46668f16caa1ec","Stock price modeling and prediction have been challenging objectives for researchers and speculators because of noisy and non-stationary characteristics of samples. With the growth in deep learning, the task of feature learning can be performed more effectively by purposely designed network. In this paper, we propose a novel end-to-end model named multi-filters neural network (MFNN) specifically for feature extraction on financial time series samples and price movement prediction task. Both convolutional and recurrent neurons are integrated to build the multi-filters structure, so that the information from different feature spaces and market views can be obtained. We apply our MFNN for extreme market prediction and signal-based trading simulation tasks on Chinese stock market index CSI 300. Experimental results show that our network outperforms traditional machine learning models, statistical models, and single-structure(convolutional, recurrent, and LSTM) networks in terms of the accuracy, profitability, and stability. © 2018 Elsevier B.V.","Deep learning; Feature engineering; Stock price prediction","Commerce; Convolution; Electronic trading; Financial markets; Forecasting; Long short-term memory; Motion estimation; Chinese stock market; Feature engineerings; Financial time series; Machine learning models; Market prediction; Non stationary characteristics; Stock price movement predictions; Stock price prediction; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068321387&doi=10.1007%2fs00521-019-04319-1&partnerID=40&md5=8f2af3404d9a2c6273c448fc607ad40a","Applying neural network and error t-value test, this study trains and analyzes 28 interest rate changes of China’s macro-monetary policy and the mutual influences between reserve adjustments and financial markets for 51 times from 2000 to 2018 according to the data correlation between financial market and monetary policy. Through the principal component analysis, the bilateral financial risk system and data set are established, and the data set pre-process and dimensionality reduction are carried out to extract the most informative features. Six training cases are designed with processed features, and then the cases are input to each neural network model for combined prediction. Firstly, based on backpropagation neural network (BP), the forecasting model of monetary policy is established. Then, considering the importance characteristics of financial index data, expert weights based on BP, are introduced to propose weights backpropagation (WBP) model. On the basis of the timing characteristics of financial market, the WBP model is improved and the timing weights backpropagation (TWBP) model is proposed. Experiments show that different training cases bring out various effects. The accuracy rate of interest rate and reserve change value is lower than the original value after training. The mutation after data processing affects the learning of neural network. At the same time, the WBP and TWBP models improve according to the importance and timing characteristics of financial indicators have less errors in results, and the TWBP model has higher accuracy. When the number of hidden layers is 3, good results can be obtained, but in manifold training of the timing cycle, the efficiency of that is not as good as the WBP model. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Financial risks; Monetary policy; Neural network; Time series","Backpropagation; Commerce; Data handling; Electronic trading; Financial markets; Forecasting; Neural networks; Principal component analysis; Risk assessment; Time series; Back-propagation neural networks; Dimensionality reduction; Financial indicator; Financial risks; Forecasting modeling; Monetary policies; Neural network model; Timing characteristics; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049119150&doi=10.1007%2f978-3-319-93701-4_31&partnerID=40&md5=e9dfe727834895fa1e23279c9d434bba","Recurrent neural network are a type of deep learning units that are well studied to extract features from sequential samples. They have been extensively applied in forecasting univariate financial time series, however their application to high frequency multivariate sequences has been merely considered. This paper solves a classification problem in which recurrent units are extended to deep architecture to extract features from multi-variance market data in 1-minutes frequency and extreme market are subsequently predicted for trading signals. Our results demonstrate the abilities of deep recurrent architecture to capture the relationship between the historical behavior and future movement of high frequency samples. The deep RNN is compared with other models, including SVM, random forest, logistic regression, using CSI300 1-minutes data over the test period. The result demonstrates that the capability of deep RNN generating trading signal based on extreme movement prediction support more efficient market decision making and enhance the profitability. © Springer International Publishing AG, part of Springer Nature 2018.","Deep learning; Financial time series; High frequency trading; Recurrent neural networks","Commerce; Decision making; Decision trees; Deep learning; Deep neural networks; Electronic trading; Forecasting; Motion estimation; Network architecture; Time series; Deep architectures; Financial time series; High frequency HF; High-frequency trading; Logistic regressions; Market prediction; Movement prediction; Random forests; Recurrent neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060437096&partnerID=40&md5=709befa654341d6b62bf303e1b800252","In this paper, we show that the recent integration of statistical models with deep recurrent neural networks provides a new way of formulating volatility (the degree of variation of time series) models that have been widely used in time series analysis and prediction in finance. The model comprises a pair of complementary stochastic recurrent neural networks: the generative network models the joint distribution of the stochastic volatility process; the inference network approximates the conditional distribution of the latent variables given the observables. Our focus here is on the formulation of temporal dynamics of volatility over time under a stochastic recurrent neural network framework. Experiments on real-world stock price datasets demonstrate that the proposed model generates a better volatility estimation and prediction that outperforms mainstream methods, e.g., deterministic models such as GARCH and its variants, and stochastic models namely the MCMC-based stochvol as well as the Gaussian-process-based, on average negative log-likelihood. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Economic analysis; Electronic trading; Recurrent neural networks; Stochastic systems; Time series analysis; Conditional distribution; Deterministic models; Gaussian Processes; Joint distributions; Stochastic recurrent neural network; Stochastic volatility; Stochastic Volatility Model; Volatility estimations; Stochastic models"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056713060&doi=10.1145%2f3243082.3264663&partnerID=40&md5=5fdb34fd55c174be2aea52ebfd616ff7","The investment market has been growing every day, performing an important role in the lives of individuals and corporations. Therefore, there is a need to better understand the situations that occur in the capital market, by means of strategies and indicators that can assist in pattern recognition, analisys and investiment decisions. This work performs a study of characterization and analysis of a historical time series data of 10 asset codes (i.e., BBAS3, USIM5, PETR4, JBSS3, KROT3, LAME4, MRVE4, NATU3, RADL3 e TIMP3) of the Bovespa index and sentiment analysis of polarity news and Twitter data with the proposal of evaluating a prediction model. It proposes the combination of deep learning and machine learning computational intelligence models for prediction, allowing the execution and cancellation of buy and sell orders. Finally, it evaluates the behavior of each proposed trading strategy by Accuracy, Percentage of Financial Return and other indicators to provide a better understanding of financial market behavior. © 2018 Copyright held by the owner/author(s).","Data characterization; Deep learning; Financial indicators; Machine learning; Stock markets; Trading strategies; Web 2.0","Artificial intelligence; Commerce; Financial markets; Investments; Learning systems; Pattern recognition; Sentiment analysis; Time series analysis; Data characterization; Financial indicator; Financial returns; Investment market; Machine learning models; Time-series data; Trading strategies; Web 2.0; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062649597&doi=10.24507%2ficicel.12.12.1277&partnerID=40&md5=8dc84360c4a58b4b41aa2bc08ec5d4d8","Time series analysis has significance in financial analytics and market forecasting and it can be utilized in any field. For stockbrokers, understanding trends and forecasting supported by software are very important to decision making and reacting to changes in behavioral patterns. This paper proposes an algorithm and model for market forecasting in Indonesian exchange based on the Long Short-Term Memory (LSTM) and compared with ARIMA model. We use data from Bank Central Asia (BCA) from 2013-2018 obtained from Yahoo finance. In our experiments, we predict and simulate the important prices called Open, High, Low and Closing (OHLC) with various parameters. Based on the experiment, the best accurate prediction in LSTM comes from the short term (1 year) with high epoch in training phase rather than using 3 years or 5 years of training data, and our model has better result compared with popular model such as ARIMA. These results should be very useful to be used in stock exchange office. © 2018, ICIC International. All rights reserved.","ARIMA; Deep learning; Finance; Forecasting; LSTM; Stock market",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068615399&doi=10.1007%2f978-3-030-22796-8_18&partnerID=40&md5=57e85658236fa53c446bb2537b5aad2b","Realized volatility (RV) is defined as the sum of the squares of logarithmic returns on high-frequency sampling grid and aggregated over a certain time interval, typically a trading day in finance. It is not a priori clear what the aggregation period should be in case of continuously traded cryptocurrencies at online exchanges. In this work, we aggregate RV values using minute-sampled Bitcoin returns over 3-h intervals. Next, using the RV time series, we predict the future values based on the past samples using a plethora of machine learning methods, ANN (MLP, GRU, LSTM), SVM, and Ridge Regression, which are compared to the Heterogeneous Auto-Regressive Realized Volatility (HARRV) model with optimized lag parameters. It is shown that Ridge Regression performs the best, which supports the auto-regressive dynamics postulated by HARRV model. Mean Squared Error values by the neural-network based methods closely follow, whereas the SVM shows the worst performance. The present benchmarks can be used for dynamic risk hedging in algorithmic trading at cryptocurrency markets. © 2019, Springer Nature Switzerland AG.","ANN; CNN; GRU; HARRV; LSTM; MLP; Realized volatility; Ridge regression; SVM","Electronic money; Electronic trading; Learning algorithms; Learning systems; Mean square error; Regression analysis; Time series; Algorithmic trading; HARRV; High-frequency sampling; LSTM; Machine learning methods; Mean squared error; Realized volatility; Ridge regression; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057188554&doi=10.1016%2fj.eswa.2018.11.027&partnerID=40&md5=5b0f6d3076cb618d8edf95b8ffef8e62","Trend change prediction in complex systems with a large number of noisy time series is a problem with many applications for real-world phenomena, with stock markets as a notoriously difficult to predict example of such systems. We approach predictions of directional trend changes via complex lagged correlations between them, excluding any information about the target series from the respective inputs to achieve predictions purely based on such correlations with other series. We propose the use of deep neural networks that employ step-wise linear regressions with exponential smoothing in the preparatory feature engineering for this task, with regression slopes as trend strength indicators for a given time interval. We apply this method to historical stock market data from 2011 to 2016 as a use case example of lagged correlations between large numbers of time series that are heavily influenced by externally arising new information as a random factor. The results demonstrate the viability of the proposed approach, with state-of-the-art accuracies and accounting for the statistical significance of the results for additional validation, as well as important implications for modern financial economics. © 2018 Elsevier Ltd","Deep learning; Lagged correlation; Stock market; Trend analysis","Commerce; Complex networks; Deep learning; Deep neural networks; Financial data processing; Financial markets; Forecasting; Time series; Change prediction; Exponential smoothing; Feature engineerings; Financial economics; Financial time series; Statistical significance; Strength indicator; Trend analysis; Real time systems"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070196844&doi=10.1007%2f978-3-030-26636-3_9&partnerID=40&md5=a8f6aba9db12e6a044fd9a932d5da4b5","Algorithmic trading approaches based on news or social network posts claim to outperform classical methods that use only price time series and other economics values. However combining financial time series with news or posts, requires daily huge amount of relevant text which are impracticable to gather in real time, even because the online sources of news and social networks no longer allow unconditional massive download of data. These difficulties have renewed the interest in simpler methods based on financial time series. This work presents a wide experimental comparisons of the performance of 7 trading protocols applied to 27 component stocks of the Dow Jones Industrial Average (DJIA). The buy/sell trading actions are driven by the stock value predictions performed with 3 types of neural network architectures: feed forward, recurrent and autoencoder. Each architecture types in turn has been experimented with different sizes and hyperparameters over all the multivariate time series. The combinations of trading protocols with variants of the 3 neural network types have been in turn applied to time series, varying the input variables from 4 to 17 and the training period from 8 to 16 years while the test period from 1 to 2 years. © 2019, Springer Nature Switzerland AG.","Autoencoder; Deep learning; Feed forward neural network; LSTM; Quantitative finance; Recurrent neural network; Stock market prediction; Trading","Commerce; Deep learning; Deep neural networks; Feedforward neural networks; Financial markets; Information management; Long short-term memory; Network architecture; Recurrent neural networks; Social networking (online); Time series; Auto encoders; Dow Jones Industrial averages; Experimental comparison; LSTM; Multivariate time series; Stock market prediction; Stock value prediction; Trading; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062213716&doi=10.1109%2fICMLA.2018.00242&partnerID=40&md5=4f5b54b41303692eefecc50b383449c3","With technological advancements, big data can be easily generated and collected in many applications. Embedded in these big data are useful information and knowledge that can be discovered by machine learning and data mining models, techniques or algorithms. A rich source of big data is stock exchange. The ability to effectively predict future stock prices improves the economic growth and development of a country. Traditional linear approaches for prediction (e.g., Kalman filters) may not be practical in handling big data like stock prices due to highly nonlinear and chaotic nature. This lead to the exploitation of various nonlinear estimators such as the extended Kalman filters, expert systems, and various neural network architectures. Moreover, to lessen the potential shortcomings of individual algorithms, ensemble approaches have been created by averaging values across different algorithms. Existing ensemble techniques mostly basket-together a collection of sample-based algorithms that are catered to nonlinear functions. To the best of our knowledge, traditional linear estimators have not yet been incorporated into such an ensemble. Hence, in this paper, we propose a machine learning (specifically, token-based ensemble) algorithm that utilizes both linear and nonlinear estimators to predict big financial time-series data. Our ensemble consists of a traditional Kalman filter, long short-term memory (LSTM) network, and the traditional linear regression model. We also explore the adaptive properties in short-term high-risk trading in the presence of noisy data like stock prices and demonstrate the performance of our ensemble. © 2018 IEEE.","Ensemble learning; Kalman filter; Linear data; Linear regression; Long short term memory (LSTM); Nonlinear data; Stock prediction; Time-series analysis","Big data; Brain; Costs; Data mining; Economics; Electronic trading; Expert systems; Filtration; Financial markets; Forecasting; Kalman filters; Learning algorithms; Linear regression; Long short-term memory; Network architecture; Predictive analytics; Regression analysis; Time series analysis; Ensemble learning; Linear data; Linear regression models; Machine learning approaches; Nonlinear data; Stock predictions; Technological advancement; Traditional Kalman filters; Machine learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960936929&doi=10.1145%2f2820426.2820467&partnerID=40&md5=f22180497819667cd69549fa92c6a454","According to the efficient market hypothesis, financial prices are unpredictable. However, meaningful advances have been achieved on anticipating market movements using machine learning techniques. In this work, we propose a novel method to represent the input for a stock price forecaster. The forecaster is able to predict stock prices from time series and additional information from web pages. Such information is extracted as structured events and represented in a compressed concept space. By using such representation with scalable forecasters, we reduced prediction error by about 10%, when compared to the traditional auto regressive models. © 2015 ACM.","Deep learning; Natural language processing; Open information extraction; Stocks forecast","Artificial intelligence; Commerce; Costs; Forecasting; Learning algorithms; Learning systems; Natural language processing systems; Time series analysis; Websites; Auto regressive models; Concept space; Deep learning; Efficient market hypothesis; Machine learning techniques; NAtural language processing; Prediction errors; Stock forecasting; Financial markets"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066033657&doi=10.1016%2fj.procs.2019.01.189&partnerID=40&md5=a782fa0d1b64f2a7424f6c185b797325","This paper proposes a C-RNN forecasting method for Forex time series data based on deep-Recurrent Neural Network (RNN) and deep Convolutional Neural Network (CNN), which can further improve the prediction accuracy of deep learning algorithm for the time series data of exchange rate. We fully exploit the spatio-temporal characteristics of forex time series data based on the data-driven method. On the exchange rate data of nine major foreign exchange currencies, the experimental comparison of the forecasting method shows that the C-RNN foreign exchange time series data prediction method constructed in this paper has better applicability and higher accuracy. © 2019 The Author(s).","Convolutional neural network; Deep learning; Foreign Exchange Rate; Recurrent neural network; Time series analysis","Convolution; Deep learning; Deep neural networks; Economics; Electronic trading; Finance; Forecasting; Internet of things; Learning algorithms; Recurrent neural networks; Convolutional neural network; Data-driven methods; Experimental comparison; Forecasting methods; Foreign exchange rates; Prediction accuracy; Recurrent neural network (RNN); Spatiotemporal characteristics; Time series analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055911654&doi=10.1007%2f978-3-030-02686-8_34&partnerID=40&md5=b4190ee83040f8cabc0d9e835c681154","This work presents a remarkable and innovative short-term forecasting method for Financial Time Series (FTS). Most of the approaches for FTS modeling work directly with prices, given the fact that transaction data is more reachable and more widely available. For this particular work, we will be using the Limit Order Book (LOB) data, which registers all trade intentions from market participants. As a result, there is more enriched data to make better predictions. We will be using Deep Convolutional Neural Networks (CNN), which are good at pattern recognition on images. In order to accomplish the proposed task we will make an image-like representation of LOB and transaction data, which will feed up into the CNN, therefore it can recognize hidden patterns to classify FTS in short-term periods. We will present step by step methodology to encode financial time series into an image-like representation. Results present an impressive performance, ranging between 63% and 66% in Directional Accuracy (DA), having advantages in reducing model parameters as well as to make inputs time invariant. © Springer Nature Switzerland AG 2019.","Convolutional Neural Networks; Deep Learning; Limit Order Book; Pattern recognition; Short-term forecasting","Commerce; Convolution; Correlation theory; Deep learning; Deep neural networks; Financial markets; Forecasting; Neural networks; Pattern recognition; Time series; Convolutional neural network; Deep convolutional neural networks; Directional accuracy; Financial time series; Limit order book; Market participants; Short-term forecasting; Stock price prediction; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054084759&doi=10.1007%2f978-3-030-00350-0_11&partnerID=40&md5=640620712b73a27da93804d09c5d7e57","This work introduces how to use Limit Order Book Data (LOB) and transaction data for short-term forecasting of stock prices. LOB registers all trade intentions from market participants, as a result, it contains more market information that could enhance predictions. We will be using Deep Convolutional Neural Networks (CNN), which are good at pattern recognition on images. In order to accomplish the proposed task we will make an image-like representation of LOB and transaction data, which will feed up into the CNN, therefore it can recognize hidden patterns to classify Financial Time Series (FTS) in short-term periods. Data enclose information from 11 NYSE instruments, including stocks, ETF and ADR. We will present step by step methodology for encoding financial time series into an image-like representation. Results present an impressive performance, 74.15% in Directional Accuracy (DA). © 2018, Springer Nature Switzerland AG.","Convolutional Neural Networks; Deep Learning; Limit Order Book; Pattern recognition; Short-term forecasting","Commerce; Convolution; Correlation theory; Deep learning; Deep neural networks; Financial markets; Forecasting; Neural networks; Pattern recognition; Time series; Convolutional neural network; Deep convolutional neural networks; Directional accuracy; Financial time series; Limit order book; Market information; Market participants; Short-term forecasting; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894900843&doi=10.1002%2ffor.2270&partnerID=40&md5=393c0adcd3e2c4d222f58e813b9b2d1c","We propose a wavelet neural network (neuro-wavelet) model for the short-term forecast of stock returns from high-frequency financial data. The proposed hybrid model combines the capability of wavelets and neural networks to capture non-stationary nonlinear attributes embedded in financial time series. A comparison study was performed on the predictive power of two econometric models and four recurrent neural network topologies. Several statistical measures were applied to the predictions and standard errors to evaluate the performance of all models. A Jordan net that used as input the coefficients resulting from a non-decimated wavelet-based multi-resolution decomposition of an exogenous signal showed a consistent superior forecasting performance. Reasonable forecasting accuracy for the one-, three- and five step-ahead horizons was achieved by the proposed model. The procedure used to build the neuro-wavelet model is reusable and can be applied to any high-frequency financial series to specify the model characteristics associated with that particular series. Copyright © 2013 John Wiley & Sons, Ltd. Copyright © 2013 John Wiley & Sons, Ltd.","high-frequency financial data; neuro-wavelets; recurrent neural networks; time series forecasting; wavelet multi-resolution decomposition",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040642723&partnerID=40&md5=8ce33cfda06ab10028aae0e4f89638b6","We propose a wavelet neural network model (neuro-wavelet) for the short-term forecast of stock returns from high-frequency financial data. The proposed hybrid model combines the inherent capability of wavelets and artificial neural networks to capture non-stationary and non-linear attributes embedded in financial time series. A comparison study was performed on the modeling and predictive power among two traditional econometric models and four different dynamic recurrent neural network architectures. Several statistical measures and tests were performed on the forecasting estimates and standard errors to evaluate the predictive performance of all models. A Jordan net which used as input to the neural network the coefficients resulting from a non-decimated Haar wavelet-based decomposition of the high and low stock prices showed consistently to have a superior modeling and predictive performance over the other models. Reasonable forecasting accuracy for one, three, and five step-ahead horizons was achieved by the Jordan neuro-wavelet model. © 2012 Newswood Limited. All rights reserved.","Dynamic neural networks; Neuro-wavelets; Time series forecasting; Wavelet decomposition","Control equipment; Electronic trading; Financial markets; Forecasting; Investments; Network architecture; Recurrent neural networks; Time series; Dynamic neural networks; Dynamic recurrent neural networks; Financial time series; Forecasting accuracy; Neuro-wavelets; Predictive performance; Time series forecasting; Wavelet neural network model; Wavelet decomposition"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069000578&doi=10.1109%2fICASSP.2019.8682297&partnerID=40&md5=2d843d9f98f084beab64a4d27a28ad0f","Forecasting time series has several applications in various domains. The vast amount of data that are available nowadays provide the opportunity to use powerful deep learning approaches, but at the same time pose significant challenges of high-dimensionality, velocity and variety. In this paper, a novel logistic formulation of the well-known Bag-of-Features model is proposed to tackle these challenges. The proposed method is combined with deep convolutional feature extractors and is capable of accurately modeling the temporal behavior of time series, forming powerful forecasting models that can be trained in an end-to-end fashion. The proposed method was extensively evaluated using a large-scale financial time series dataset, that consists of more than 4 million limit orders, outperforming other competitive methods. © 2019 IEEE.","Limit Order Book; Temporal Bag-of-Features; Time series forecasting",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057427978&doi=10.1007%2f978-981-13-2285-3_58&partnerID=40&md5=2b93f79ac8906e6742573ab27ac710aa","Financial Analysis has become a challenging aspect in today’s world of valuable and better investment. This paper introduces the implementation of Recurrent Neural Network (RNN) along with Long Short-Term Memory Cells (LSTM) for Stock Market Prediction used for Portfolio Management considering the Time Series Historical Stock Data of Stocks in the Portfolio. The comparison of the model with the traditional Machine Learning Algorithms—Regression, Support Vector Machine, Random Forest, Feed Forward Neural Network and Backpropagation have been performed. Various metrics and architectures of LSTM RNN model have been considered and are tested and analysed. There is discussion on how the sentiments of the customer would affect the stocks along with the changes in trends. © 2019, Springer Nature Singapore Pte Ltd.","Long short-term memory; Portfolio optimization; Recurrent neural network; Trading","Backpropagation algorithms; Brain; Commerce; Decision trees; Electronic trading; Financial markets; Information management; Investments; Learning algorithms; Recurrent neural networks; Financial analysis; Portfolio managements; Portfolio optimization; Recurrent neural network (RNN); Short term memory; Stock market prediction; Stock market prices; Trading; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056525695&doi=10.1109%2fIJCNN.2018.8489425&partnerID=40&md5=8f97d8879b71aacf283f9c3c82d6e298","Financial time series forecasting is considered to be one of the most challenging areas in current time series analysis theory. This complexity is caused mainly by the multitude of factors that influence the series and the volatility of this factors, which means that predicting models must adapt to a wide range of circumstances. Yet, the possibility of great financial return makes it a field of great interest for many researchers. Recently, non-linear techniques have been widely used for the construction of forecasting models, due to its ability to access higher order statistics. In particular, neural networks have shown to greatly enhance classical predicting models, and over the past years Deep Learning techniques are on the rise since computational power and data availability are becoming less of a constraint. This paper aims to compare the use of deep learning methods over shallow neural networks when predicting next day closing prices of stocks traded in the Brazilian financial market. Moreover, simulations using recent historical data are performed so that the models' profitability can be assessed and compared with the well-known strategy of Buy and Hold. © 2018 IEEE.",,"Commerce; Deep learning; Electronic trading; Finance; Forecasting; Higher order statistics; Computational power; Data availability; Financial returns; Financial time series forecasting; Forecasting models; Learning techniques; Non-linear methods; Nonlinear techniques; Time series analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049694522&doi=10.1109%2fICRITO.2017.8342391&partnerID=40&md5=cd3b90e443df072c8196bbe4ef1e1825","The theory of fuzzy (F)-transforms relates to a modern mathematical modeling. It provides a (dimensionally) reduced and robust representation of original data. It is based on a granulation of a domain (fuzzy partition) and gives a tractable image of an original data. The main characteristics with respect to input data: size reduction, noise removal, invariance to geometrical transformations, knowledge transfer from conventional mathematics, fast computation. The F-transform has been applied to: image processing, computer vision, on-line pattern recognition in big data bases, time series analysis and forecasting, mathematical finance, numerical methods for differential equations, deep learning neural networks. In this contribution, we show that the technique of F-transforms fully agrees with the technique of dimensionality reduction, based on Laplacian eigenmaps. In the application part, we give an overview of the F-transform applications to mathematical finance. © 2017 IEEE.","basic function; Black-Scholes equation; dimensionality reduction; F-transform; fuzzy partition; Laplacian eigenmaps; market volatility","Big data; Computation theory; Data mining; Deep learning; Differential equations; Finance; Image processing; Knowledge management; Laplace transforms; Numerical methods; Pattern recognition; Time series analysis; Basic functions; Black Scholes equations; Dimensionality reduction; F transforms; Fuzzy partition; Laplacian eigenmaps; Market volatility; Data reduction"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062493875&partnerID=40&md5=6128dfb4e3f0c1510e797f915b05d201","Many real-world financial time series forecasting problems share a unique property: the focal variable of interests can be decomposed into a large number of accounting component variables. For example, company earnings are calculated from total revenue minus total costs and each variable can be further decomposed into several accounting items. This property leads to a relatively new research problem. When the dependent variable for prediction has a hierarchical structure, which level of aggregation may be the optimal choice for prediction? Is it possible to use the information from the predictions of all component variables to enhance the prediction accuracy of the focal variable of interests? To solve this problem, this paper designs a novel forecasting method-Hierarchical Stacking of LSTM (HSL)-by using various data mining techniques. Our proposed solution consists of two stages. In the first phase, by LSTM-RNN, the proposed method makes predictions of the dependent variable given different candidate decompositions. Meanwhile, we devise a method creative use of Genetic algorithm to search for the top-performing decompositions of the dependent variable. In the second stage, the ensemble learning method by Stacking is applied to aggregate several predictions from top-performing decompositions. An empirical evaluation on earning forecast of public companies illustrates that HSL can outperform other existing methods. © International Conference on Information Systems 2018, ICIS 2018.All rights reserved.","Deep Learning; Fintech; Forecast; Hierarchical Accounting Variables","Data mining; Financial data processing; Forecasting; Genetic algorithms; Information systems; Information use; Long short-term memory; Problem solving; Dependent variables; Empirical evaluations; Financial time series forecasting; Fintech; Forecasting methods; Hierarchical Accounting Variables; Hierarchical structures; Prediction accuracy; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054192390&doi=10.1016%2fj.inffus.2018.07.007&partnerID=40&md5=1c6a547ca8cff51e1d8151180dfa36fb","Accurate time-series forecasting is vital for numerous areas of application such as transportation, energy, finance, economics, etc. However, while modern techniques are able to explore large sets of temporal data to build forecasting models, they typically neglect valuable information that is often available under the form of unstructured text. Although this data is in a radically different format, it often contains contextual explanations for many of the patterns that are observed in the temporal data. In this paper, we propose two deep learning architectures that leverage word embeddings, convolutional layers and attention mechanisms for combining text information with time-series data. We apply these approaches for the problem of taxi demand forecasting in event areas. Using publicly available taxi data from New York, we empirically show that by fusing these two complementary cross-modal sources of information, the proposed models are able to significantly reduce the error in the forecasts. © 2018 Elsevier B.V.","Cross modality learning; Data fusion; Deep learning; Special events; Taxi demand; Textual data; Time series forecasting; Urban mobility","Data fusion; Forecasting; Taxicabs; Time series; Cross modality; Special events; Taxi demand; Textual data; Time series forecasting; Urban mobility; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006230902&doi=10.1016%2fj.jksuci.2015.06.002&partnerID=40&md5=73c576be060a20cd37a90f84a9e1a22d","The paper presents a low complexity recurrent Functional Link Artificial Neural Network for predicting the financial time series data like the stock market indices over a time frame varying from 1 day ahead to 1 month ahead. Although different types of basis functions have been used for low complexity neural networks earlier for stock market prediction, a comparative study is needed to choose the optimal combinations of these for a reasonably accurate forecast. Further several evolutionary learning methods like the Particle Swarm Optimization (PSO) and modified version of its new variant (HMRPSO), and the Differential Evolution (DE) are adopted here to find the optimal weights for the recurrent computationally efficient functional link neural network (RCEFLANN) using a combination of linear and hyperbolic tangent basis functions. The performance of the recurrent computationally efficient FLANN model is compared with that of low complexity neural networks using the Trigonometric, Chebyshev, Laguerre, Legendre, and tangent hyperbolic basis functions in predicting stock prices of Bombay Stock Exchange data and Standard & Poor's 500 data sets using different evolutionary methods and has been presented in this paper and the results clearly reveal that the recurrent FLANN model trained with the DE outperforms all other FLANN models similarly trained. © 2015 The Authors","Differential Evolution; Hybrid Moderate Random Search PSO; Low complexity FLANN models; Recurrent computationally efficient FLANN",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050024627&doi=10.1109%2fICIINFS.2017.8300345&partnerID=40&md5=0bfcbb19de3509c8080dd6f85c2a18a6","Recurrent Neural Networks (RNNs) is a sub type of neural networks that use feedback connections. Several types of RNN models are used in predicting financial time series. This study was conducted to develop models to predict daily stock prices of selected listed companies of Colombo Stock Exchange (CSE) based on Recurrent Neural Network (RNN) Approach and to measure the accuracy of the models developed and identify the shortcomings of the models if present. Feedforward, Simple Recurrent Neural Network (SRNN), Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM) architectures were employed in building models. Closing, High and Low prices of past two days were selected as input variables for each company. Feedforward networks produce the highest and lowest forecasting errors. The forecasting accuracy of the best feedforward networks is approximately 99%. SRNN and LSTM networks generally produce lower errors compared with feedforward networks but in some occasions, the error is higher than feed forward networks. Compared to other two networks, GRU networks are having comparatively higher forecasting errors. © 2017 IEEE.","Colombo Stock Exchange; GRU; LSTM; Recurrent Neural Networks; SRNN","Costs; Electronic trading; Errors; Financial markets; Forecasting; Information systems; Information use; Recurrent neural networks; Feed-forward network; Financial time series; LSTM; Recurrent neural network (RNN); Recurrent neural network (RNNs); Simple recurrent neural networks; SRNN; Stock exchange; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042664127&doi=10.1109%2fICACCI.2017.8126078&partnerID=40&md5=2a94646ff60f434ad6dcdbfd32e95fef","Stock market or equity market have a profound impact in today's economy. A rise or fall in the share price has an important role in determining the investor's gain. The existing forecasting methods make use of both linear (AR,MA,ARIMA) and non-linear algorithms (ARCH,GARCH,Neural Networks),but they focus on predicting the stock index movement or price forecasting for a single company using the daily closing price. The proposed method is a model independent approach. Here we are not fitting the data to a specific model, rather we are identifying the latent dynamics existing in the data using deep learning architectures. In this work we use three different deep learning architectures for the price prediction of NSE listed companies and compares their performance. We are applying a sliding window approach for predicting future values on a short term basis.The performance of the models were quantified using percentage error. © 2017 IEEE.","CNN; LSTM; RNN; Stock market; Time series","Commerce; Costs; Deep learning; Economics; Electronic trading; Finance; Financial markets; Forecasting; Investments; Network architecture; Time series; Forecasting methods; Learning architectures; LSTM; Model independent; Percentage error; Price forecasting; Sliding window models; Stock price prediction; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059063545&doi=10.1007%2f978-981-13-1747-7_46&partnerID=40&md5=5456523bfa8ee2771d6611ca2bcd87a2","This paper attempts to provide an optimal model for the prediction of stock prices for t + 5th day and consequently provide a daily buying/selling strategy for the Standard’s and Poor’s 500 Index. A performance comparison between LSTM, GRU, ANN and SVM model has been made and an optimal model has been outlined. Training and prediction data spanned over 12 years from 2000 to 2017. Fifty technical indicator-based attributes were calculated and appended to the open, high, low, close and volume (OHLCV) data for S&P500, each attribute value was converted into a relative standard score followed by minimax scaling and dimensionality reduction, through ICA. Performances of different models on this dataset were then compared using self-defined metrics like optimism and pessimism ratio and returns ratio. The LSTM model proved to outperform the other models with a return of 400% greater than the hold and wait strategy and R2 score of 0.9486. © Springer Nature Singapore Pte Ltd. 2019.","Artificial neural networks (ANN); Financial time series forecasting; Gated recurrent unit (GRU); Independent components analysis (ICA); Long short-term memory (LSTM); Support vector machines (SVM)","Data communication systems; Electronic trading; Financial markets; Forecasting; Independent component analysis; Intelligent systems; Neural networks; Optimization; Support vector machines; Time series analysis; Attribute values; Dimensionality reduction; Financial time series forecasting; Gated recurrent unit (GRU); Independent components analysis; Performance comparison; Stock price prediction; Technical indicator; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048331794&doi=10.1016%2fj.asoc.2018.04.024&partnerID=40&md5=eda5e0eb866c3d90e39146b522f49a85","Computational intelligence techniques for financial trading systems have always been quite popular. In the last decade, deep learning models start getting more attention, especially within the image processing community. In this study, we propose a novel algorithmic trading model CNN-TA using a 2-D convolutional neural network based on image processing properties. In order to convert financial time series into 2-D images, 15 different technical indicators each with different parameter selections are utilized. Each indicator instance generates data for a 15 day period. As a result, 15 × 15 sized 2-D images are constructed. Each image is then labeled as Buy, Sell or Hold depending on the hills and valleys of the original time series. The results indicate that when compared with the Buy & Hold Strategy and other common trading systems over a long out-of-sample period, the trained model provides better results for stocks and ETFs. © 2018 Elsevier B.V.","Algorithmic trading; Convolutional neural networks; Deep learning; Financial forecasting; Stock market; Technical analysis","Commerce; Convolution; Deep learning; Deep neural networks; Financial markets; Image processing; Neural networks; Time series; Algorithmic trading; Algorithmic trading models; Computational intelligence techniques; Convolutional neural network; Deep convolutional neural networks; Financial forecasting; Financial trading system; Technical analysis; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876945790&doi=10.1016%2fj.engappai.2012.12.012&partnerID=40&md5=5f347f9eb23714b55314f901058ff03b","This paper examines electricity price time series from dynamical system perspective and proposes a hybrid model which employs a synergistic combination of Recurrent Neural Network (RNN) and coupled excitable system for prediction of future prices in deregulated electricity markets. Driven by profit maximizing decisions taken by various agents, these markets belong to the class of financial systems. However presence of intermittent spikes and complex dynamic nonlinearities in electricity price time series render the prediction task extremely challenging. The approximation ability of Recurrent Neural Networks to map dynamic functions together with sharp jumping attribute of coupled excitable systems allows close approximation of spiky time series. The developed hybrid model was applied for point and interval forecasting in various markets worldwide over different seasons for testing its adaptability in different environments. Satisfactory prediction results were obtained in all the markets, in stable as well as spiking regions of the time series. © 2013 Elsevier Ltd.","Excitable system; FHN coupled system; Multiple scale dynamics; Recurrent neural networks","Coupled systems; Deregulated electricity market; Excitable systems; Hybrid intelligent model; Multiple scale; Recurrent neural network (RNN); Satisfactory predictions; Synergistic combinations; Commerce; Costs; Dynamical systems; Profitability; Recurrent neural networks; Time series; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056656183&doi=10.1016%2fj.procs.2018.04.298&partnerID=40&md5=fae82407faee2859f988f9e47d759522","Gated recurrent unit (GRU) networks perform well in sequence learning tasks and overcome the problems of vanishing and explosion of gradients in traditional recurrent neural networks (RNNs) when learning long-term dependencies. Although they apply essentially to financial time series predictions, they are seldom used in the field. To fill this void, we propose GRU networks and its improved version for predicting trading signals for stock indexes of the Hang Seng Indexes (HSI), the Deutscher Aktienindex (DAX) and the S&P 500 Index from 1991 to 2017, and compare the GRU-based models with the traditional deep net and the benchmark classifier support vector machine (SVM). Experimental results show that the two GRU models proposed in this paper both obtain higher prediction accuracy on these data sets, and the improved version can effectively improve the learning ability of the model. © 2018 The Authors. Published by Elsevier Ltd.","Deep learning; Financial time series; GRU; Stock index; SVM","Financial data processing; Financial markets; Forecasting; Recurrent neural networks; Support vector machines; Time series; Financial time series; Financial time series predictions; Learning abilities; Long-term dependencies; Prediction accuracy; Recurrent neural network (RNNs); Sequence prediction; Stock indices; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049670640&doi=10.1109%2fTKDE.2018.2854193&partnerID=40&md5=533b3ce311e3efbb3cffe99494caf059","The recent advance of deep learning has enabled trading algorithms to predict stock price movements more accurately. Unfortunately, there is a significant gap in the real-world deployment of this breakthrough. For example, professional traders in their long-term careers have accumulated numerous trading rules, the myth of which they can understand quite well. On the other hand, deep learning models have been hardly interpretable. This paper presents DeepClue, a system built to bridge text-based deep learning models and end users through visually interpreting the key factors learned in the stock price prediction model. We make three contributions in DeepClue. First, by designing the deep neural network architecture for interpretation and applying an algorithm to extract relevant predictive factors, we provide a useful case on what can be interpreted out of the prediction model for end users. Second, by exploring hierarchies over the extracted factors and displaying these factors in an interactive, hierarchical visualization interface, we shed light on how to effectively communicate the interpreted model to end users. Specially, the interpretation separates the predictables from the unpredictables for stock prediction through the use of intercept model parameters and a risk visualization design. Third, we evaluate the integrated visualization system through two case studies in predicting the stock price with financial news and company-related tweets from social media. Quantitative experiments comparing the proposed neural network architecture with state-of-the-art models and the human baseline are conducted and reported. Feedbacks from an informal user study with domain experts are summarized and discussed in details. The study results demonstrate the effectiveness of DeepClue in helping to complete stock market investment and analysis tasks. © 1989-2012 IEEE.","Deep learning; model interpretation; stock prediction; visualization","Commerce; Costs; Data visualization; Deep learning; Deep neural networks; Financial markets; Flow visualization; Forecasting; Human computer interaction; Investments; Learning algorithms; Learning systems; Network architecture; Neural networks; Time series analysis; Visualization; Integrated visualization systems; Model interpretations; Prediction algorithms; Predictive models; Quantitative experiments; Stock predictions; Stock price movements; Stock price prediction; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062240139&doi=10.1109%2fICMLA.2018.00227&partnerID=40&md5=cd3c7fb3c393f6e2bd5e8de7c43b2422","Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as 'Long Short-Term Memory (LSTM)', are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as 'epoch' in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior. © 2018 IEEE.","Autoregressive Integrated Moving Average (ARIMA); Deep Learning; Forecasting; Long Short-Term Memory (LSTM); Time Series Data","Brain; Deep learning; Forecasting; Long short-term memory; Machine learning; Time series; Auto-regressive integrated moving average; Computational power; Empirical studies; Forecasting time series; Learning-based algorithms; Research questions; Simple exponential smoothing; Time-series data; Learning algorithms"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067255101&doi=10.1109%2fACCESS.2019.2912823&partnerID=40&md5=ed76d5ab033a4740f780824051bde9fb","This paper presents a novel framework for the demystification of convolutional deep learning models for time-series analysis. This is a step toward making informed/explainable decisions in the domain of time series, powered by deep learning. There have been numerous efforts to increase the interpretability of image-centric deep neural network models, where the learned features are more intuitive to visualize. Visualization in the domain of time series is significantly challenging, as there is no direct interpretation of the filters and inputs compared with the imaging modality. In addition, a little or no concentration has been devoted to the development of such tools in the domain of time series in the past. TSViz provides possibilities to explore and analyze the network from different dimensions at different levels of abstraction, which includes the identification of the parts of the input that were responsible for a particular prediction (including per filter saliency), importance of the different filters present in the network, notion of diversity present in the network through filter clustering, understanding of the main sources of variation learned by the network through inverse optimization, and analysis of the network's robustness against adversarial noise. As a sanity check for the computed influence values, we demonstrate our results on pruning of neural networks based on the computed influence information. These representations allow the user to better understand the network so that the acceptability of these deep models for time-series analysis can be enhanced. This is extremely important in domains, such as finance, industry 4.0, self-driving cars, health care, and counter-terrorism, where reasons for reaching a particular prediction are equally important as the prediction itself. We assess the proposed framework for interpretability with a set of desirable properties essential for any method in this direction. © 2019 IEEE.","convolutional neural networks; Deep learning; demystification; feature importance; representation learning; time-series analysis; time-series forecasting; visualization","Convolution; Deep learning; Deep neural networks; Flow visualization; Forecasting; Harmonic analysis; Inverse problems; Neural networks; Terrorism; Visualization; Convolutional neural network; demystification; feature importance; representation learning; Time series forecasting; Time series analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006504040&doi=10.1007%2fs11042-016-4159-7&partnerID=40&md5=d5a422175c2383460758ac58c479e5b4","Stock market is considered chaotic, complex, volatile and dynamic. Undoubtedly, its prediction is one of the most challenging tasks in time series forecasting. Moreover existing Artificial Neural Network (ANN) approaches fail to provide encouraging results. Meanwhile advances in machine learning have presented favourable results for speech recognition, image classification and language processing. Methods applied in digital signal processing can be applied to stock data as both are time series. Similarly, learning outcome of this paper can be applied to speech time series data. Deep learning for stock prediction has been introduced in this paper and its performance is evaluated on Google stock price multimedia data (chart) from NASDAQ. The objective of this paper is to demonstrate that deep learning can improve stock market forecasting accuracy. For this, (2D) 2 PCA + Deep Neural Network (DNN) method is compared with state of the art method 2-Directional 2-Dimensional Principal Component Analysis (2D) 2 PCA + Radial Basis Function Neural Network (RBFNN). It is found that the proposed method is performing better than the existing method RBFNN with an improved accuracy of 4.8% for Hit Rate with a window size of 20. Also the results of the proposed model are compared with the Recurrent Neural Network (RNN) and it is found that the accuracy for Hit Rate is improved by 15.6%. The correlation coefficient between the actual and predicted return for DNN is 17.1% more than RBFNN and it is 43.4% better than RNN. © 2016, Springer Science+Business Media New York.","(2D) 2 PCA; Deep Learning; Multimedia; Neural Network; Radial Basis Function Neural Network; Regularization; Stock Prediction","Artificial intelligence; Commerce; Complex networks; Electronic trading; Finance; Financial markets; Forecasting; Functions; Image classification; Learning systems; Neural networks; Radial basis function networks; Recurrent neural networks; Signal processing; Speech recognition; Time series; (2D) <sup>2</sup> PCA; Deep learning; Multimedia; Radial basis function neural networks; Regularization; Stock predictions; Principal component analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068677237&doi=10.1080%2f14697688.2019.1622295&partnerID=40&md5=b7aa4082d05477e65a52a513cdddf343","Using a large-scale Deep Learning approach applied to a high-frequency database containing billions of market quotes and transactions for US equities, we uncover nonparametric evidence for the existence of a universal and stationary relation between order flow history and the direction of price moves. The universal price formation model exhibits a remarkably stable out-of-sample accuracy across a wide range of stocks and time periods. Interestingly, these results also hold for stocks which are not part of the training sample, showing that the relations captured by the model are universal and not asset-specific. The universal model—trained on data from all stocks—outperforms asset-specific models trained on time series of any given stock. This weighs in favor of pooling together financial data from various stocks, rather than designing asset- or sector-specific models, as is currently commonly done. Standard data normalizations based on volatility, price level or average spread, or partitioning the training data into sectors or categories such as large/small tick stocks, do not improve training results. On the other hand, inclusion of price and order flow history over many past observations improves forecast accuracy, indicating that there is path-dependence in price dynamics. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Deep learning; Financial econometrics; High-frequency data; Intraday data; Limit order book; Machine learning; Market microstructure; Price formation",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068552387&doi=10.1109%2fEBBT.2019.8741818&partnerID=40&md5=5bd120d0c934452e0fc6a6521877b323","In recent years, due to the technological improvements in computers' hardware and enhancements in the machine learning techniques, there are two increasing approaches for problem-solving as the use of 'Big Data' and 'Parallel Processing'. Especially with the emergence of Deep Learning algorithms which can be executed parallelly on multi-core computing devices such as GPUs and CPUs, lots of real-world problems are resolved with these approaches. One of the most critical application areas in the Financial Market especially sits on Stock Markets. In this area, the aim is trying to predict the future value of a specific stock by looking at its previous financial data on the exchange process in the market. In this paper, we proposed a system that uses a Deep Learning based approach for training and constructing a knowledge base on a specific stock such as 'IBM'. We get time series values of the stock from the New York Stock Exchange which starts from 1968 up to 2018. Experimental results showed that this approach produces very good forecasting for specific stocks. © 2019 IEEE.","Big data; Deep learning; Forecasting; Stock exchange","Big data; Biomedical engineering; Commerce; Data Analytics; Electronic medical equipment; Engineering education; Financial markets; Forecasting; Knowledge based systems; Learning algorithms; Problem solving; Program processors; Critical applications; Learning-based approach; Machine learning techniques; Multi-core computing; New York Stock Exchange; Parallel processing; Stock exchange; Technological improvements; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051127390&doi=10.1007%2f978-3-319-96893-3_11&partnerID=40&md5=7f7a85066dfcec4b8c100548b85ca3c0","Time series prediction is not easy to achieve high accuracy. non-linear and unstable characteristics make the time series prediction difficult. The variety of dataset make the prediction result debatable. In order to solve this problem, in this paper we propose a deep learning prediction method based on decomposition, reconstruction and combination, which combines ways of communication field. The model is decomposed by Empirical Mode Decomposition, Principal Component Analysis and Long Short-Term Memory networks (EPL below). And also, the proposed interval EPL (IEPL below) improve and consummate the EPL model. The EPL and IEPL experiment results will bring average 5% higher accuracy than that of existing research. © 2018, Springer International Publishing AG, part of Springer Nature.","Deep learning; EPL; IEPL; Time series prediction","Deep learning; Financial data processing; Financial markets; Forecasting; Information management; Principal component analysis; Time series; Combined model; Communication fields; Empirical Mode Decomposition; High-accuracy; IEPL; Prediction methods; Short term memory; Time series prediction; Big data"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049006277&doi=10.1007%2f978-3-319-93713-7_55&partnerID=40&md5=bee7c24b30308effb49836edb7ea9052","A hybrid ensemble learning approach is proposed to forecast financial time series combining AdaBoost algorithm and Long Short-Term Memory (LSTM) network. Firstly, by using AdaBoost algorithm the database is trained to get the training samples. Secondly, the LSTM is utilized to forecast each training sample separately. Thirdly, AdaBoost algorithm is used to integrate the forecasting results of all the LSTM predictors to generate the ensemble results. Two major daily exchange rate datasets and two stock market index datasets are selected for model evaluation and comparison. The empirical results demonstrate that the proposed AdaBoost-LSTM ensemble learning approach outperforms some other single forecasting models and ensemble learning approaches. This suggests that the AdaBoost-LSTM ensemble learning approach is a highly promising approach for financial time series data forecasting, especially for the time series data with nonlinearity and irregularity, such as exchange rates and stock indexes. © 2018, Springer International Publishing AG, part of Springer Nature.","AdaBoost algorithm; Ensemble learning; Financial time series forecasting; Long short-term memory network","Adaptive boosting; Brain; Electronic trading; Finance; Forecasting; Sampling; Time series; AdaBoost algorithm; Ensemble learning; Ensemble learning approach; Financial time series; Financial time series forecasting; Forecasting models; Short term memory; Stock market index; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055451449&doi=10.1145%2f3231884.3231887&partnerID=40&md5=8f6bfd4d54fce1c7dd9e9175832f5ebe","Predicting the trend of stock market prices is a very challengingtask, in that stock markets are complicated and can be influencedby a variety of factors. Despite the great difficulty, predicting thetrend of stock market prices accurately is very meaningful and canbring a large amount of profit. In the past several decades, a lot ofstudies have been done on this problem. But most of the methodstake only the historic prices data as the input, which is not enoughfor such a complicated problem. In this paper, a hybrid methodtaking both historic prices and the news as input is proposed. Thehybrid model combines the best of two kinds of networks-RNN-LSTM for time series data and CNN for abstract highdimensional data. These two different kinds of networks arecombined together to make a prediction. A set of experimentshave been carried out to show the performance of the proposedmethod. The result obtained is promising, and the propose methodachieves a great degree of accuracy in prediction and outperformsthe baselines a lot. © 2018 Association for Computing Machinery.","Combined data; Convolution neural network; Hybrid algorithm; Long-short term memory; Stock market prediction","Commerce; Costs; Electronic trading; Financial markets; Forecasting; Learning systems; Combined data; Convolution neural network; Degree of accuracy; High dimensional data; Hybrid algorithms; Stock market prediction; Stock market prices; Time-series data; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063296627&doi=10.1109%2fICA-SYMP.2019.8645980&partnerID=40&md5=6d0d55814771a4a69014332f019d5392","We propose a spatio-temporal model for predicting anomaly price movements in the Stock Exchange of Thailand (SET). The model used a deep neural network classification algorithm that has a time series of of limit order books (LOB) as an input. There were three output classes: anomaly price uptrend, anomaly price downtrend, and normal price movements. We performed experiments to compare the efficiency among convolutional neural network model, Long short-term memory model, and the combination of both in order to classify anomaly price movements. The results of the experiment showed that the combination of both convolutional layers and Long short-term memory model had the highest accuracy with 74.55% for predicting abnormal price movements. © 2019 IEEE.","anomaly detection; deep neural network; spatiotemporal model","Anomaly detection; Brain; Convolution; Correlation theory; Electronic trading; Financial markets; Long short-term memory; Robotics; Convolutional neural network; Limit order book; Neural network classification; Price movement; Short term memory; Spatio-temporal models; Stock Exchange of Thailand; Deep neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054237730&doi=10.1515%2fjisys-2018-0074&partnerID=40&md5=7967b47342579c69fa41c2d63c74d23e","Deep learning is an effective approach to solving image recognition problems. People draw intuitive conclusions from trading charts. This study uses the characteristics of deep learning to train computers in imitating this kind of intuition in the context of trading charts. The main goal of our approach is combining the time-series modeling and convolutional neural networks (CNNs) to build a trading model. We propose three steps to build the trading model. First, we preprocess the input data from quantitative data to images. Second, we use a CNN, which is a type of deep learning, to train our trading model. Third, we evaluate the model's performance in terms of the accuracy of classification. The experimental results show that if the strategy is clear enough to make the images obviously distinguishable the CNN model can predict the prices of a financial asset. Hence, our approach can help devise trading strategies and help clients automatically obtain personalized trading strategies. ©2018 Walter de Gruyter GmbH, Berlin/Boston 2018.","convolutional neural network (CNN); Deep learning; Forex (FX); geometric Brownian motion (GBM); trading strategies","Brownian movement; Commerce; Convolution; Deep learning; Image recognition; Neural networks; Accuracy of classifications; Convolutional neural network; Convolutional Neural Networks (CNN); Effective approaches; Forex (FX); Geometric Brownian motion; Time series modeling; Trading strategies; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059781356&doi=10.1109%2fICPR.2018.8545666&partnerID=40&md5=63a2fd52394522fad4c748b5415d4dca","The prediction of financial time series data is a challenging task due to the unpredictable behaviours of investors that are influenced by a multitude of factors. In this paper, we present a novel deep Long Short-Term Memory (LSTM) based time-series data modelling for use in stock market index prediction. A dataset comprised of six market indices from around the world were chosen to demonstrate the robustness in varying market conditions with an aim to forecast the next day closing price. With experimental results showing an average annual profitability performance of up to 200%, our method demonstrates its feasibility and significant results in time-series modelling and prediction of financial markets. © 2018 IEEE.",,"Commerce; Electronic trading; Financial markets; Forecasting; Investments; Pattern recognition; Time series; Financial time series; Market condition; Stock market index; Time-series data; Time-series modelling; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041471618&doi=10.23919%2fEUSIPCO.2017.8081663&partnerID=40&md5=e72dae24bfa282d0e93feec563c60389","Forecasting financial time-series has long been among the most challenging problems in financial market analysis. In order to recognize the correct circumstances to enter or exit the markets investors usually employ statistical models (or even simple qualitative methods). However, the inherently noisy and stochastic nature of markets severely limits the forecasting accuracy of the used models. The introduction of electronic trading and the availability of large amounts of data allow for developing novel machine learning techniques that address some of the difficulties faced by the aforementioned methods. In this work we propose a deep learning methodology, based on recurrent neural networks, that can be used for predicting future price movements from large-scale high-frequency time-series data on Limit Order Books. The proposed method is evaluated using a large-scale dataset of limit order book events. © EURASIP 2017.",,"Commerce; Correlation theory; Finance; Financial data processing; Financial markets; Forecasting; Investments; Learning systems; Recurrent neural networks; Signal processing; Stochastic models; Stochastic systems; Time series; Time series analysis; Forecasting accuracy; Forecasting financial time series; High frequency time series; Large amounts of data; Large-scale dataset; Machine learning techniques; Qualitative method; Stochastic nature; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029406625&doi=10.1109%2fCBI.2017.23&partnerID=40&md5=022dc1842b9f21a67fdfe96c9ec1389e","In today's financial markets, where most trades are performed in their entirety by electronic means and the largest fraction of them is completely automated, an opportunity has risen from analyzing this vast amount of transactions. Since all the transactions are recorded in great detail, investors can analyze all the generated data and detect repeated patterns of the price movements. Being able to detect them in advance, allows them to take profitable positions or avoid anomalous events in the financial markets. In this work we proposed a deep learning methodology, based on Convolutional Neural Networks (CNNs), that predicts the price movements of stocks, using as input large-scale, high-frequency time-series derived from the order book of financial exchanges. The dataset that we use contains more than 4 million limit order events and our comparison with other methods, like Multilayer Neural Networks and Support Vector Machines, shows that CNNs are better suited for this kind of task. © 2017 IEEE.","Convolutional Neural Networks; Large scale financial data; Limit Orderbook","Commerce; Convolution; Correlation theory; Costs; Finance; Financial data processing; Financial markets; Investments; Multilayer neural networks; Neural networks; Anomalous events; Convolutional neural network; Financial data; Forecasting stock prices; High frequency time series; Limit Orderbook; Price movement; Repeated patterns; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046136407&doi=10.1109%2fSSCI.2017.8285188&partnerID=40&md5=7bfe2ccbc04a9056d8c47b517a9f1262","The success of convolutional neural networks in the field of computer vision has attracted the attention of many researchers from other fields. One of the research areas in which neural networks is actively used is financial forecasting. In this paper, we propose a novel method for predicting stock price movements using CNN. To avoid the high volatility of the market and to maximize the profit, ETFs are used as primary financial assets. We extract commonly used trend indicators and momentum indicators from financial time series data and use these as our features. Adopting a sliding window approach, we generate our images by taking snapshots that are bounded by the window over a daily period. We then perform daily predictions, namely, regression for predicting the ETF prices and classification for predicting the movement of the prices on the next day, which can be modified to estimate weekly or monthly trends. To increase the number of images, we use numerous ETFs. Finally, we evaluate our method by performing paper trading and calculating the final capital. We also compare our method's performance to commonly used classical trading strategies. Our results indicate that we can predict the next day's prices with 72% accuracy and end up with 5:1 of our initial capital, taking realistic values of transaction costs into account. © 2017 IEEE.",,"Commerce; Costs; Deep learning; Financial markets; Forecasting; Neural networks; Convolutional neural network; Financial assets; Financial forecasting; Financial time series; Stock price movements; Stock trading model; Trading strategies; Transaction cost; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062733197&doi=10.1109%2fIBIGDELFT.2018.8625357&partnerID=40&md5=4e8d5d6a02ffc9af758c900dc71f62f2","Technical analysis is a widely used method for forecasting the price direction on the financial time series data. This method requires the use of different number and types of analysis algorithms (technical indicators) together. Although these algorithms show successful performance on small-scalefinancial time series data, significant performance decreases are detected when the size of data increased. On the large-scale financial time series data, it is necessary to implement these algorithms based on the Map-Reduce programming model and examine the performance of the algorithms which are implemented based on this model comparatively. For this purpose, seven different indicators are studied within the scope of this study, new versions of these indicators are implemented using Map-Reduce parallel data processing model and performance comparisons are made with these algorithms. As a result of these comparisons on single-node and multi-node, significant performance gains have been obtained using Map-Reduce programming model. © 2018 IEEE.","Financial Time Series Data; Map-Reduce Programming Model; Technical Analysis; Technical Analysis Indicators","Big data; Deep learning; Finance; Financial data processing; Terrorism; Time series; Time series analysis; Analysis algorithms; Financial time series; Map-reduce programming; Parallel data processing; Performance comparison; Technical analysis; Technical indicator; Time-series data; Data reduction"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061162689&doi=10.1016%2fj.neucom.2019.01.092&partnerID=40&md5=17a6773bf1cac120eb3a6d95d37ad7f2","In recent years, artificial neural networks have been employed a lot in forecasting financial price series. Crude oil and natural gas play the most important role in energy markets. Besides, crude oil price fluctuations are closely linked to financial markets. A novel hybrid neural network, DPFWR neural network, is put forward in this paper. The proposed DPFWR combines double parallel feedforward neural network and wavelet analysis theory with a random time effective function. We apply the DPFWR to forecast the energy futures price time series, including WTI crude oil, Brent crude oil, natural gas, RBOB gasoline, heating oil and Rotterdam coal. In order to compare the accuracy of forecasting results, several error criteria are applied to evaluate the forecasting errors of BP, DPF, LSTM, DPFWR and SARIMA models. A new method for error evaluation, called DS-CID, is developed to evaluate the forecasting errors in an attempt to observe the superiority of DPFWR neural network. Based on the empirical analysis, the forecast performance of DPFWR can be distinguished from other models by its great accuracy in this research. © 2019 Elsevier B.V.","Double-scale complexity invariant Distance; DPFWR neural network; Energy futures price series; Forecast; Random time effective function; Wavelet analysis","Commerce; Costs; Crude oil; Electronic trading; Errors; Feedforward neural networks; Financial markets; Forecasting; Function evaluation; Natural gas; Time series analysis; Wavelet analysis; Double-scale; Effective function; Empirical analysis; Energy future; Forecast performance; Hybrid neural networks; Oil and natural gas; Prices forecasting; Long short-term memory; coal; gasoline; natural gas; oil; petroleum; Article; artificial neural network; back propagation; double parallel feedforward neural network; double scale complexity invariant distance; energy cost; forecasting; long short term memory network; market; mathematical analysis; measurement accuracy; predictive value; priority journal; seasonal autoregressive integrated moving average; time series analysis; wavelet analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973369468&doi=10.1155%2f2016%2f4742515&partnerID=40&md5=747323508b1e5f3cc3b32e249cf23b48","In recent years, financial market dynamics forecasting has been a focus of economic research. To predict the price indices of stock markets, we developed an architecture which combined Elman recurrent neural networks with stochastic time effective function. By analyzing the proposed model with the linear regression, complexity invariant distance (CID), and multiscale CID (MCID) analysis methods and taking the model compared with different models such as the backpropagation neural network (BPNN), the stochastic time effective neural network (STNN), and the Elman recurrent neural network (ERNN), the empirical results show that the proposed neural network displays the best performance among these neural networks in financial time series forecasting. Further, the empirical research is performed in testing the predictive effects of SSE, TWSE, KOSPI, and Nikkei225 with the established model, and the corresponding statistical comparisons of the above market indices are also exhibited. The experimental results show that this approach gives good performance in predicting the values from the stock market indices. © 2016 Jie Wang et al.",,"Commerce; Electronic trading; Financial markets; Forecasting; Stochastic models; Stochastic systems; Time series; Time series analysis; Back-propagation neural networks; Effective function; Elman recurrent neural network; Empirical research; Financial time series forecasting; Financial time series predictions; Random neural network; Statistical comparisons; Recurrent neural networks; algorithm; artificial neural network; commercial phenomena; computer simulation; economic model; human; Markov chain; predictive value; time factor; trends; Algorithms; Commerce; Computer Simulation; Humans; Models, Economic; Neural Networks (Computer); Predictive Value of Tests; Stochastic Processes; Time Factors"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060291651&doi=10.1109%2fDCABES.2018.00052&partnerID=40&md5=54730e1ce60ace450e876f689e6f1c7d","In this paper, we mainly study the application of Long Short-Term Memory (LSTM) algorithms in the stock market. LSTM originates from the recurrent neural network (RNN) and has a significant effect on the time series problems. In this paper, the BP neural network model and the LSTM model are established respectively. Then we combine them with the stock data, a series of prediction results are obtained. Obviously, the prediction results of LSTM model are more accurate, and the prediction accuracy rate can reach 60%-65%. In the modeling process, in order to solve the 'saw-tooth phenomenon' of the gradient descent algorithm which is inevitable, we have improved the traditional gradient descent algorithm and specially designed the input data of the neural network. In addition, we defined a parameter combination library and use the skill of dropout to get the more ideal prediction results. © 2018 IEEE.","BP neural network; LSTM; stock forecasting","Distributed computer systems; Electronic trading; Financial markets; Forecasting; BP neural network model; BP neural networks; Gradient descent algorithms; LSTM; Parameter combination; Recurrent neural network (RNN); Stock forecasting; Stock price forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866037441&partnerID=40&md5=cbc8b4fed2822efa33a1896507342cfa","Recently, many academy researchers have proposed several forecasting models by technical analysis to forecast stocks, such as (Yamawaki & Tokuoka 2007) [1]. The traditional approach uses a linear time series model for stock forecasting. However, the results would be in doubt when the forecasting problems are nonlinear. Multifeature data from financial statements usually produce high-dimensional data, and therefore, the proposed model utilizes synthesis feature selection for reducing the number of dimensions. The proposed hybrid model utilizes synthesis feature selection to optimize the recurrent network (RNN) for predicting stock price trends. Three refined processes are proposed in the hybrid model for forecasting: (1) select essential technical indicators from popular indicators by a correlation matrix; (2) use stepwise regression and a decision tree to reduce features; and (3) utilize a recurrent neural network (Elman neural network) to build a forecasting model. A six-year period of the Taiwan stock exchange capitalization weighted stock index (TAIEX) is employed as a verification database to evaluate the proposed model under a performance indicator, root mean squared error (RMSE). The results show that the proposed model is superior to the listing models. © 2012 ICIC International.","Recurrent neural network; Synthesis feature; Technical indicators","Correlation matrix; Elman neural network; Financial statements; Forecasting models; Forecasting problems; High dimensional data; Hybrid model; Linear time series model; Neural networks model; Performance indicators; Recurrent networks; Root mean squared errors; Stepwise regression; Stock exchange; Stock forecasting; Stock indices; Stock price; Synthesis features; Taiwan stock markets; Technical analysis; Technical indicator; Benchmarking; Decision trees; Finance; Recurrent neural networks; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063269215&doi=10.1109%2fACCESS.2019.2901842&partnerID=40&md5=bf89de3a4ec99b9bdbc6121c9deac89a","Given a financial time series such as S&P 500, or any historical data in stock markets, how can we obtain useful information from recent transaction data to predict the ups and downs at the next moment? Recent work on this issue shows initial evidence that machine learning techniques are capable of identifying (non-linear) dependency in the stock market price sequences. However, due to the high volatility and non-stationary nature of the stock market, forecasting the trend of a financial time series remains a big challenge. In this paper, we introduced a new method to simplify noisy-filled financial temporal series via sequence reconstruction by leveraging motifs (frequent patterns), and then utilize a convolutional neural network to capture spatial structure of time series. The experimental results show the efficiency of our proposed method in feature learning and outperformance with 4%-7% accuracy improvement compared with the traditional signal process methods and frequency trading patterns modeling approach with deep learning in stock trend prediction. © 2019 IEEE.","convolutional neural network; financial time series; motif extraction; Trend prediction","Commerce; Convolution; Deep learning; Electronic trading; Forecasting; Information use; Machine learning; Neural networks; Signal processing; Time series; Accuracy Improvement; Convolutional neural network; Financial time series; Machine learning techniques; Sequence reconstruction; Stock market prices; Stock trend prediction; Trend prediction; Financial markets"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069515246&doi=10.1007%2fs10660-019-09362-7&partnerID=40&md5=a6413203ef4a7417fe2b94eb4955f83b","Cash flow prediction is important. It can help increase returns and improve the allocation of capital in healthy, mature firms as well as prevent fast-growing firms, or firms in distress, from running out of cash. In this paper, we predict accounts receivable cash flows employing methods applicable to companies with many customers and many transactions such as e-commerce companies, retailers, airlines and public transportation firms with sales in multiple regions and countries. We first discuss “classic” forecasting techniques such as ARIMA and Facebook's™ Prophet before moving on to neural networks with multi-layered perceptrons and, finally, long short-term memory networks, that are particularly useful for time series forecasting but were until now not used for cash flows. Our evaluation demonstrates this range of methods to be of increasing sophistication, flexibility and accuracy. We also introduce a new performance measure, interest opportunity cost, that incorporates interest rates and the cost of capital to optimize the models in a financially meaningful, money-saving, way. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Accounts receivable; ARIMA; Cash flow prediction; LSTM; MLP; Neural networks; Prophet",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062887338&doi=10.1109%2fICDMW.2018.00032&partnerID=40&md5=24fda9f037e89099768764af286a5549","Long short-term memory (LSTM) networks are a state-of-the-art sequence learning in deep learning for time series forecasting. However, less study applied to financial time series forecasting especially in cryptocurrency prediction. Therefore, we propose a new forecasting framework with LSTM model to forecasting bitcoin daily price with two various LSTM models (conventional LSTM model and LSTM with AR(2) model). The performance of the proposed models are evaluated using daily bitcoin price data during 2018/1/1 to 2018/7/28 in total 208 records. The results confirmed the excellent forecasting accuracy of the proposed model with AR(2). The test mean squared error (MSE), root mean square error (RMSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for bitcoin price prediction, respectively. The our proposed LSTM with AR(2) model outperformed than conventional LSTM model. The contribution of this study is providing a new forecasting framework for bitcoin price prediction can overcome and improve the problem of input variables selection in LSTM without strict assumptions of data assumption. The results revealed its possible applicability in various cryptocurrencies prediction, industry instances such as medical data or financial time-series data. © 2018 IEEE.","Bitcoin; cryptocurrency prediction; long-short term memory (LSTM)","Bitcoin; Brain; Correlation theory; Data mining; Deep learning; Errors; Financial data processing; Forecasting; Mean square error; Time series; Financial time series; Financial time series forecasting; Forecasting accuracy; Input variables selections; Mean absolute error; Mean absolute percentage error; Root mean square errors; Time series forecasting; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063733190&doi=10.1016%2fj.knosys.2019.03.029&partnerID=40&md5=76fd451e919da1400fbff4fcdb82e3cb","Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled using Variational Bayes via the data generation and inference operations. We benchmark our model with 9 other popular ones in terms of the likelihood of forecasts given the observed sequence. Experimental results suggest that our model not only outperforms pure statistical models, e.g., GARCH and its variants, Gaussian-process volatility model, but also outperforms the state-of-the-art autoregressive deep neural nets architectures, such as the variational recurrent neural network and the neural stochastic volatility model. © 2019 Elsevier B.V.","Financial text mining; Sentiment knowledge; Time series analysis; Variational neural networks; Volatility modeling","Commerce; Data mining; Deep neural networks; Economic analysis; Forecasting; Harmonic analysis; Investments; Recurrent neural networks; Signal processing; Stochastic systems; Time series analysis; Bi-directional interaction; Financial forecasting; Financial text minings; Sentiment knowledge; Statistical inference; Stochastic Volatility Model; Volatility forecasting; Volatility modeling; Stochastic models"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037095689&doi=10.1007%2fs11277-017-5086-2&partnerID=40&md5=5147fe533db6fb35ee507c8621585fde","By combining wavelet analysis with Long Short-Term Memory (LSTM) neural network, this paper proposes a time series prediction model to capture the complex features such as non-linearity, non-stationary and sequence correlation of financial time series. The LSTM is then applied to the prediction of the daily closing price of the Shanghai Composite Index as well as the comparison of its prediction ability with machine learning models such as multi-layer perceptron, support vector machine and K-nearest neighbors. The empirical results show that the LSTM performs a better prediction effect, and it shows excellent effects on the static prediction and dynamic trend prediction of the financial time series, which indicates its applicability and effectiveness to the prediction of financial time series. At the same time, both wavelet decomposition and reconstruction of financial time series can improve the generalization ability of the LSTM prediction model and the prediction accuracy of long-term dynamic trend. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; Financial time series prediction; Long Short-Term Memory neural network; Wavelets","Brain; Deep learning; Finance; Financial data processing; Forecasting; Nearest neighbor search; Time series; Time series analysis; Wavelet decomposition; Decomposition and reconstruction; Financial time series; Financial time series predictions; Generalization ability; Machine learning models; Multi layer perceptron; Time series prediction; Wavelets; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067471318&doi=10.1109%2fICCCBDA.2019.8725661&partnerID=40&md5=f66b4db2f9cc552158b4f6de0c7b8551","The world economy is in a stage of rapid development, and financial development is also continuing. Financial activities are increasing, and the uncertainty of its changing trend is also increasing. An effective financial forecast can provide a basis for financial planning and decision-making while maintaining the healthy development of financial markets. Convolution neural network is a multilayer neural network structure that simulates the operation mechanism of biological vision system. It is a neural network composed of multiple layers of convolution layers and down sampling layers. It can obtain useful feature descriptions from raw data and is an effective method for extracting features from data. Therefore, this paper introduces the convolution neural network structure to predict the financial time series data, establishes a convolution neural network model, and studies the influence of model parameters on the stock prediction results. Through simulation and comparison, the feasibility and effectiveness of the prediction model given in this paper are verified. © 2019 IEEE.","convolutional neural network; financial forecasting; stock forecasting; support vector machine","Advanced Analytics; Big data; Cloud computing; Convolution; Decision making; Electronic trading; Forecasting; Multilayer neural networks; Support vector machines; Biological vision systems; Convolution neural network; Convolutional neural network; Extracting features; Financial development; Financial forecasting; Financial time series; Stock forecasting; Finance"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064804694&partnerID=40&md5=a5c1279b3a556a8fc2637088296762c1","We propose a parsimonious quantile regression framework to learn the dynamic tail behaviors of financial asset returns. Our model captures well both the time-varying characteristic and the asymmetrical heavy-tail property of financial time series. It combines the merits of a popular sequential neural network model, i.e., LSTM, with a novel parametric quantile function that we construct to represent the conditional distribution of asset returns. Our model also captures individually the serial dependences of higher moments, rather than just the volatility. Across a wide range of asset classes, the out-of-sample forecasts of conditional quantiles or VaR of our model outperform the GARCH family. Further, the proposed approach does not suffer from the issue of quantile crossing, nor does it expose to the ill-posedness comparing to the parametric probability density function approach. © 2018 Curran Associates Inc.All rights reserved.",,"Finance; Financial data processing; Probability density function; Conditional distribution; Conditional quantiles; Financial asset returns; Financial time series; Out-of-sample forecast; Sequential learning; Sequential neural networks; Time-varying characteristics; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059057328&doi=10.1007%2f978-3-030-04221-9_4&partnerID=40&md5=248636f953ec85405b587d1f4d8e2d50","Stock index prediction is regarded as a challenging task due to the phenomena of non-linearity and random drift in trends of stock indices. In practical applications, different indicator features have significant impact when predicting stock index. In addition, different technical indicators which contained in the same matrix will interfere with each other when convolutional neural network (CNN) is applied to feature extraction. To solve the above problem, this paper suggests a multi-indicator feature selection for stock index prediction based on a multi-channel CNN structure, named MI-CNN framework. In this method, candidate indicators are selected by maximal information coefficient feature selection (MICFS) approach, to ensure the correlation with stock movements while reduce redundancy between different indicators. Then an effective CNN structure without sub-sampling is designed to extract abstract features of each indicator, avoiding mutual interference between different indicators. Extensive experiments support that our proposed method performs well on different stock indices and achieves higher returns than the benchmark in trading simulations, providing good potential for further research in a wide range of financial time series prediction with deep learning based approaches. © 2018, Springer Nature Switzerland AG.","Convolutional neural networks; Feature selection; Maximal information coefficient; Stock index prediction","Convolution; Deep learning; Finance; Financial data processing; Forecasting; Neural networks; Convolutional neural network; Convolutional Neural Networks (CNN); Financial time series predictions; Learning-based approach; Maximal information; Mutual interference; Stock index predictions; Technical indicator; Feature extraction"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067398528&doi=10.1109%2fACCESS.2019.2919189&partnerID=40&md5=fd1d14081522b0376634f091a934d27a","Appropriate monetary liquidity is important for financial institutions. When institutions lack adequate cash flow for customer redemption, their income will decrease, their reputation will be affected, and they may even go bankrupt. However, the opposite extreme in which more cash is reserved than needed may result in lost opportunities to make successful investments. This study uses Yu'e Bao transaction data to investigate a method for forecasting financial capital flow. Yu'e Bao, which is a financial product launched by Alibaba, faces the core challenge of maximizing commercial profits to reduce investment risks. Liquidity risk is considered the main factor in Yu'e Bao's investment strategy. First, a linear model called YEB-ARIMA is proposed by determining the autocorrelation (ACF) and partial autocorrelation (PACF) parameters, which are optimized by the grid search method. Second, a deep learning model called YEB-LSTM is introduced to strengthen the expressiveness of the model that yields nonlinear transaction features. Then, a hybrid learning method called YEB-Hybrid is applied to improve the original weak classifiers. This model includes both a linear combination and logistic regression learning. Third, a set of experiments and analyses are conducted based on subscription and redemption datasets to demonstrate that the hybrid model achieves an accuracy of 84.39% and 84.36%, respectively, under a variety of evaluation indexes. Finally, various proposed fund reserve ratios are provided based on capital forecasts. © 2013 IEEE.","ARIMA; big data financial analysis; capital flow prediction; Liquidity risk; LSTM; time series","Autocorrelation; Economics; Forecasting; Investments; Long short-term memory; Risk assessment; Time series; Time series analysis; ARIMA; Capital flow; Financial analysis; Liquidity risk; LSTM; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055483678&doi=10.1109%2fICCSE.2018.8468703&partnerID=40&md5=87c36e4d47cef3084769cd98b1514304","The prediction of price trend in stock market is a challenging task due to the inherent complexity and dynamics in price movement. Many machine learning algorithms, such as Support Vector Machine, Artificial Neural Network, and Hidden Markov Model, have been applied to it and achieved positive results. Long Short-Term Memory (LSTM), as a variant of RNN, can obtain hidden dependencies in data and has shown a significant performance in processing time series data. In this paper, we apply LSTM networks to predict the price movement of a short-term and test it by an experiment on some stocks randomly selected from CSI 300 constituent stocks. The experiment shows that the precision, recall rate and critical error of LSTM are all better than that of the random prediction. It indicates that LSTM can be used in the trend prediction of stock price. We also notice that many improvements need to be done in future. © 2018 IEEE.","Financial time series; Long Short-Term Memory; Trend prediction","Brain; Data handling; Education computing; Electronic trading; Financial markets; Forecasting; Hidden Markov models; Learning algorithms; Learning systems; Time series; Financial time series; High frequency HF; Inherent complexity; Price movement; Price trends; Processing time; Trend forecast; Trend prediction; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070561213&doi=10.3390%2fapp9152980&partnerID=40&md5=a3a82c448fac752236218cf90c165e0b","Financial time series analysis is an important research area that can predict various economic indicators such as the foreign currency exchange rate. In this paper, a deep-learning-based model is proposed to forecast the foreign exchange rate. Since the currency market is volatile and susceptible to ongoing social and political events, the proposed model incorporates event sentiments to accurately predict the exchange rate. Moreover, as the currency market is heavily dependent upon highly volatile factors such as gold and crude oil prices, we considered these sensitive factors for exchange rate forecasting. The validity of the model is tested over three currency exchange rates, which are Pak Rupee to US dollar (PKR/USD), British pound sterling to US dollar (GBP/USD), and Hong Kong Dollar to US dollar (HKD/USD). The study also shows the importance of incorporating investor sentiment of local and foreign macro-level events for accurate forecasting of the exchange rate. We processed approximately 5.9 million tweets to extract major events' sentiment. The results show that this deep-learning-based model is a better predictor of foreign currency exchange rate in comparison with statistical techniques normally employed for prediction. The results present evidence that the exchange rate of all the three countries is more exposed to events happening in the US. © 2019 by the authors.","Deep learning; Event sentiment; Forecasting; Foreign exchange rate; Regression; SVM",
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066631662&doi=10.1109%2fINFOMAN.2019.8714662&partnerID=40&md5=e8aeb6d2dd566309691021b20213eb21","Stock market is one of the most important components of the financial system. It directs money from investors to support the activity and development of the associated company. Therefore, understanding and modeling the stock price dynamics become critically important, in terms of financial system stability, investment strategy, and market risk control. To better model the temporal dynamics of stock price, we propose a combined machine learning framework with information theory and Artificial Neural Network (ANN). This method creatively uses information entropy to inform non-linear causality as well as stock relevance and uses it to facilitate the ANN time series modeling. Our analysis with Google, Amazon, Facebook, and Apple stock prices demonstrates the feasibility of this machine learning framework. © 2019 IEEE.","LSTM; Neural network; Stock prediction; Transfer entropy","Commerce; Electronic trading; Financial markets; Information management; Information theory; Investments; Machine learning; Neural networks; System stability; Information entropy; Investment strategy; LSTM; Stock predictions; Stock price prediction; Temporal dynamics; Time series modeling; Transfer entropy; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046676132&doi=10.1109%2fICSAI.2017.8248523&partnerID=40&md5=4cb2ecd4f629295041a27cdf657e180b","Most of the existing literature on stock price analysis is based on the historical price of a single stock, where models are trained to identify the pattern of price movements and, predict future stock the prices. However, the stock price is not an isolated variable. It is correlated with and influenced by many factors. These factors are highly time dependent, it which means that the stock price movement is also time dependent. Therefore, existing prediction models often fail in applications. In this paper, our model is not based on single stock. Instead, we study a class of stocks with similar historical price movements. We get the training and forecast data of the prediction model based on time series window sliding. We then train a CART (Classification and Regression Trees) and evaluate the model on testing data. Compared with the classical models for price movement forecast including the time series analysis model ARIMA (Autoregressive Integrated Moving Average) and the recursive neural network model LSTM (Long-Short Term Memory), our l empirical results support the effectiveness of the proposed method in the stock trend forecast. © 2017 IEEE.","ARIMA; CART; Similar Stock; Slide Window; Stock Data","Costs; Forecasting; Long short-term memory; Time series analysis; Trees (mathematics); ARIMA; CART; Similar Stock; Slide windows; Stock data; Financial markets"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034241812&doi=10.1007%2f978-3-319-68612-7&partnerID=40&md5=8326b77ee3960deaa3eb0efe915413d1","The Artificial Neural Network is widely applied to the forecasting of financial time series, and has got certain effects. The problem, however, is that most of these methods is based on daily trading data. When facing the high frequency trading data which is more powerful in short-term forecasting, these methods become incapable. Inspired by the development of Convolutional Neural Network in image recognition tasks, this paper tries to apply the Convolutional Neural Network on the high frequency financial trading data, and has achieved good results. We collect the close price of Shanghai Composite Index from 2006 to 2008 and from 2014 to 2015, about 1000 trading days in total. The frequency of the trading data is 5 min. The paper intends to forecast the stock’s future trend of the next day from historical data, namely, go up or down. First, we apply Hodrick-Prescott decomposition [1] on the original time series. The Hodrick-Prescott filter(decomposition) is a mathematical tool used in macroeconomics to separate the cyclical component ct and trend component τt from a time series. After preprocessing, the proposed method novelly transforms the time series into pictures. We apply GASF, GADF and MTF algorithm [2] on the time series respectively, forming the R, G and B channels of a picture. By transforming each of the time series into picture mode, the trading time series produces a picture library. Finally, the proposed method uses AlexNet architecture as feature extractor and classifier. The net has five convolution layers, three pooling layers, and two fully-connected layers. In data set of time series from 2006 to 2008, we choose the training data and the testing data randomly, and the proposed method can keep the accuracy at about 0.55 on the binary classification problem. In data set of time series from 2014 to 2015, we choose the last 16 training days of the data set as testing data and the accuracy can reach up to 0.60. © Springer International Publishing AG 2017.","Convolutional neural network; Stock forecasting","Commerce; Convolution; Economics; Electronic trading; Financial data processing; Forecasting; Image recognition; Learning systems; Neural networks; Statistical tests; Time series; Binary classification problems; Convolutional neural network; Financial time series; High-frequency trading; Hodrick-prescott filters; Mathematical tools; Short-term forecasting; Stock forecasting; Classification (of information)"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064682040&doi=10.1109%2fBIGCOMP.2019.8679218&partnerID=40&md5=ac3380240e6e59ec5d26054649bb4bc8","This paper presents a novel deep learning approach for the stock price prediction using a cycle embeddings with attention mechanism (CEAM) applying on Dual-Stage Attention-Based RNN (DA-RNN) model. The cycle characteristic is an important factor in time series prediction problem since it affects the trend of stock price. Thus, an effective cycle information can improve the prediction performance of stock price. In past years, many researches use the cycle feature with other features together as equally important, which might dilute the weight of cycle information since the cycle information should be paid more attention when making prediction on periodic data. As the result, we use CEAM making prediction with cycle information hidden in periodic data. The deep learning-based method has been developed in many fields and is a powerful prediction system. In addition, many researches use the embeddings feature and the attention mechanism to improve the prediction performance. In this paper, we propose a novel approach to capture the cycle information and use it to predict stock prices in U.S. stock market. The cycle information can be formed as a distributed vector as embeddings, called cycle embeddings. The CEAM approach use cycle embeddings to pay attention on periodically historical time series data by learning the cycle semantic relations between cycle characteristics and historical stock prices to optimize the prediction model. Therefore, the CEAM approach can improve the prediction performance for stock price. The experiments in this paper show that our proposed CEAM approach outperforms the another model which combines cycle feature with other features together as equally important. © 2019 IEEE.","attention mechanism; cycle embeddings; deep recurrent neural network; stock price prediction; time series","Big data; Costs; Deep learning; Embeddings; Financial markets; Recurrent neural networks; Semantics; Time series; Attention mechanisms; Cycle characteristic; Learning-based methods; Prediction performance; Prediction systems; Semantic relations; Stock price prediction; Time series prediction; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064689405&doi=10.1007%2fs00521-019-04212-x&partnerID=40&md5=b20c85b350e360b4d046477044b58715","Understanding the pattern of financial activities and predicting their development and changes are research hotspots in academic and financial circles. Because financial data contain complex, incomplete and fuzzy information, predicting their development trends is an extremely difficult challenge. Fluctuations in financial data depend on a myriad of correlated constantly changing factors. Therefore, predicting and analysing financial data are a nonlinear, time-dependent problem. Deep neural networks (DNNs) combine the advantages of deep learning (DL) and neural networks and can be used to solve nonlinear problems more satisfactorily compared to conventional machine learning algorithms. In this paper, financial product price data are treated as a one-dimensional series generated by the projection of a chaotic system composed of multiple factors into the time dimension, and the price series is reconstructed using the time series phase-space reconstruction (PSR) method. A DNN-based prediction model is designed based on the PSR method and a long- and short-term memory networks (LSTMs) for DL and used to predict stock prices. The proposed and some other prediction models are used to predict multiple stock indices for different periods. A comparison of the results shows that the proposed prediction model has higher prediction accuracy. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Deep learning; Financial data prediction; Neural networks; Phase-space reconstruction","Chaotic systems; Deep learning; Electronic trading; Financial markets; Forecasting; Learning algorithms; Machine learning; Neural networks; Object oriented programming; Conventional machines; Financial data; Long and short term memory; Phase space reconstruction; Phase space reconstructions (PSR); Prediction accuracy; Stock price prediction; Time-dependent problem; Deep neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904512745&doi=10.1080%2f08839514.2014.923174&partnerID=40&md5=d800bc1849a9b6c538a9b566b082d9e3","Forecasting the foreign exchange rate is an uphill task. Numerous methods have been used over the years to develop an efficient and reliable network for forecasting the foreign exchange rate. This study utilizes recurrent neural networks (RNNs) for forecasting the foreign currency exchange rates. Cartesian genetic programming (CGP) is used for evolving the artificial neural network (ANN) to produce the prediction model. RNNs that are evolved through CGP have shown great promise in time series forecasting. The proposed approach utilizes the trends present in the historical data for its training purpose. Thirteen different currencies along with the trade-weighted index (TWI) and special drawing rights (SDR) is used for the performance analysis of recurrent Cartesian genetic programming-based artificial neural networks (RCGPANN) in comparison with various other prediction models proposed to date. The experimental results show that RCGPANN is not only capable of obtaining an accurate but also a computationally efficient prediction model for the foreign currency exchange rates. The results demonstrated a prediction accuracy of 98.872 percent (using 6 neurons only) for a single-day prediction in advance and, on average, 92% for predicting a 1000 days exchange rate in advance based on ten days of data history. The results prove RCGPANN to be the ultimate choice for any time series data prediction, and its capabilities can be explored in a range of other fields. © 2014 Taylor & Francis Group, LLC.",,"Economics; Finance; Genetic algorithms; Genetic programming; Mathematical models; Recurrent neural networks; Time series; Cartesian genetic programming; Computationally efficient; Foreign exchange rates; Performance analysis; Prediction accuracy; Recurrent neural network (RNNs); Reliable Networks; Time series forecasting; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149351825&doi=10.1109%2fICNC.2010.5584802&partnerID=40&md5=6ded483645aaa58382571c992573a37c","Neural networks have been popular in time series prediction in financial area for their advantages in handling nonlinear systems. However, conventional neural networks are confronted with the problem to include time property and the risk of local convergence. This paper presents a study of using a novel recurrent neural network-Echo State Network (ESN) to predict next value in a financial time series. In order to prove the predictability of financial time series, we attain the Hurst exponent through rescaled range (R/S) analysis first. In feature selection, technical analysis is utilized to extract underlying information in the time series and principal component analysis (PCA) helps to filter noise and obtain faithful representation of principle components. The data of six major stock indices in the world, DJIA, S&P 500, NASDAQ, HSI, FTSE 100 and NIKKEI 225, are employed to test our model. For comparison purpose, other neural networks such as back-propagation network and Elman network are also considered. Experiment results demonstrate that ESN performs much better than other neural networks in forecasting the next closing price and the combination of PCA with technical analysis improves the prediction accuracy a little comparing with a model using only raw price data. Our preliminary study also suggests that ESN is effective in short-term financial time series prediction and worth further investigation. © 2010 IEEE.","Echo State Network; Financial time series; Principle component analysis; Technical analysis","Feature extraction; Finance; Financial data processing; Forecasting; Recurrent neural networks; Time series; Time series analysis; Backpropagation network; Echo state networks; Elman network; Feature selection; Filter noise; Financial time series; Financial time series predictions; Hurst exponents; Local Convergence; Prediction accuracy; Principle component; Principle component analysis; Rescaled range analysis; Stock indices; Technical analysis; Time properties; Time series prediction; Principal component analysis"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052234200&doi=10.1007%2f978-3-319-99365-2_41&partnerID=40&md5=1c18057878c94f3d4fc64c9d33dcd3c0","The time series of stock prices are non-stationary and non-linear, making the prediction of future price trends much challenging. Inspired by Convolutional Neural Network (CNN), we make convolution on the time dimension to capture the long-term fluctuation features of stock series. To learn long-term dependencies of stock prices, we combine the time convolution with Long Short-Term Memory (LSTM), and propose a novel deep learning model named Time Convolution Long Short-Term Memory (TC-LSTM) networks. TC-LSTM can obtain the stock longer data dependence and overall change pattern. The experiments on two real market datasets demonstrate that the proposed model outperforms other three baseline models in the mean square error. © 2018, Springer Nature Switzerland AG.","Long Short-Term Memory (LSTM); Stock price prediction; Time convolution","Brain; Convolution; Costs; Deep learning; Financial markets; Forecasting; Mean square error; Baseline models; Change patterns; Convolutional Neural Networks (CNN); Data dependence; Long-term dependencies; Short term memory; Stock price prediction; Time convolution; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070276611&doi=10.1007%2fs13042-019-00994-7&partnerID=40&md5=bd9e3773c00442234b69465ef431719d","Noisy and nonstationary real-world time series predictions (TSPs) are challenging tasks. Confronted with these challenging tasks, the predictive power of traditional shallow models is commonly not satisfactory enough. While the research on deep learning (DL) has made milestone breakthrough in recent years, and DL paradigm has gradually become indispensable for accomplishing these complex tasks. In this work, a cascading deep architecture based on weak results (DeepCascade-WR) is established, which possesses deep models’ marked capability of feature representation learning based on complex data. In DeepCascade-WR, weak prediction results are defined, innovating the forecasting mode of traditional TSP. The original data will be properly reconstituted with prior knowledge, generating attribute vectors with valid predictive information. DeepCascade-WR possesses online learning ability and effectively avoids the retraining problem, owing to the property of OS-ELM, one base model of DeepCascade-WR. Besides, ELM is exploited as another base model of DeepCascade-WR, therefore, DeepCascade-WR naturally inherits some valuable virtues from ELM, including faster training speed, better generalization ability and the avoidance of being fallen into local optima. Ultimately, in the empirical results, DeepCascade-WR demonstrates its superior predictive performance on five benchmark financial datasets, i.e., ^DJI, ^GSK, ^HSI, JOUT, and S&P 500 Index, compared with its base learners and other state-of-the-art algorithms. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning (DL); Extreme learning machine (ELM); Online sequential extreme learning machine (OS-ELM); Time series prediction (TSP); Weak results","Benchmarking; E-learning; Forecasting; Knowledge acquisition; Machine learning; Time series; Extreme learning machine; Feature representation; Online sequential extreme learning machine; Predictive information; Predictive performance; State-of-the-art algorithms; Time series prediction; Weak results; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014019024&doi=10.1007%2fs10586-017-0803-x&partnerID=40&md5=4c82e6feed2758a33b15f83ef6379745","Social network media analytics is showing promise for prediction of financial markets. However, the true value of such data is unclear due to a lack of consensus on which instruments can be predicted. In this paper, we investigate whether measurements of collective emotional states derived from large scale network feeds are correlated to the stock transaction data over time. The information space corresponding to stocks is divided into the network public opinion space Opinion_Space and the realistic transaction space Behavior_Space. We then handle the information and generate the multidimensional time series from them respectively. Furthermore, Granger causality analysis and information theory measures are used to find and demonstrate that social media sentiments contain statistically significant ex-ante information on the future prices. At last, we propose our separate-LSTM model and the experimental results of six stocks which are randomly selected indicate that financial data predictions can be significantly improved through our model by the fusion of network public opinion emotions and realistic transaction data. © 2017, Springer Science+Business Media New York.","Emotions; Granger causality; LSTM; Network public opinion; Predictive analysis; Stock transaction; Time dependence","Commerce; Finance; Financial data processing; Financial markets; Forecasting; Information theory; Predictive analytics; Social aspects; Statistical tests; Emotions; Granger Causality; LSTM; Network public opinions; Stock transaction; Time dependence; Investments"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046799040&doi=10.1109%2fPDCAT.2017.00024&partnerID=40&md5=eee5c32c282d08a17c0cc635c6d55df6","To predicate the future with high accuracy is a holy grail in financial market. However, the volatility of chaotic financial market challenges new technologies from computer science to economic science all the time. Recently, Recurrent Neural Network (RNN) plays a new role in financial market prediction. However, results from RNN are restricted by sample size of training datasets, and show predication accuracy can hardly be guaranteed in a long term. On the other hand, Representative Pattern Discovery (RPD) is an effective way in long-term prediction while it is ineffective in short-term prediction. In this paper, we define a representative pattern for time series, and propose a fusion financial prediction strategy based on RNN and RPD. We take the advantages of both RNN and RPD, in the way that the proposed strategy is stateful to keep the short-term trend and it rectifies the predication by a time-dependent incremental factor in a long-term way. Compared with RNN and pattern discovery respectively, our experimental results demonstrate that our proposed strategy performs much better than that of others. It can increase the prediction accuracy by 6% on the basis of RNN at most, but at a cost of higher Mean Squared Error. © 2017 IEEE.","Financial prediction; Fusion method; Representative pattern discovery; RNNs","Commerce; Distributed computer systems; Financial markets; Mean square error; Recurrent neural networks; Financial prediction; Fusion methods; Long-term prediction; Prediction accuracy; Recurrent neural network (RNN); Representative patterns; RNNs; Short term prediction; Forecasting"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055477715&doi=10.1109%2fCOMPSAC.2018.10292&partnerID=40&md5=e4aaea0763cd4676186c4d8a2affd78d","The combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have played important roles in deep learning in recent years to improve the prediction performance, especially in the context of temporal data analysis. Previous research has shown that certain time series could have common time-dependent characteristics. Therefore, in order to make good prediction, it is necessary to take into account the correlation between different temporal data in modeling. However, general RNN models have serious limitation to achieve this goal. In this paper, a new architecture, Deep and Wide Neural Networks (DWNN), is proposed, where CNN's convolution layer is added to the RNN's hidden state transfer process. CNN is combined with RNN to extract the correlation characteristics of different RNN models while RNNs running along the time steps. This new architecture not only has the depth of RNN in the time dimension, but also has the width of the number of temporal data. The intuition behind the DWNN model, as well as different kinds of DWNN model structures are discussed in this paper. We use stock data from the sandstorm sector of Shanghai Stock Exchange for our experiment. As shown in the result, our proposed DWNN model can reduce the prediction mean squared error by 30% compared with the general RNN model. © 2018 IEEE.","CNNs; Convolution layer; Correlated temporal data; DNNs; RNNs","Application programs; Convolution; Deep learning; Electronic trading; Financial markets; Forecasting; Mean square error; Model structures; Network architecture; Storms; CNNs; Convolutional neural network; DNNs; Prediction mean-squared errors; Recurrent neural network (RNNs); RNNs; Temporal Data; Time-dependent characteristics; Recurrent neural networks"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049044403&doi=10.1007%2f978-3-319-93803-5_58&partnerID=40&md5=ef63080563365f325992f2f047ace6bc","Stock prediction is a great challenge for the past decades because of the fact that it is a non-stationary, noisy, chaotic environment. Traditional stock prediction models including statistical and machine learning based methods almost use handcrafted features as input. With the development of deep learning, end-to-end models achieve state-of-the-art in many other tasks. However financial time series data is too noise to apply end-to-end models straightly, instead of predicting stocks’ absolute future return, we propose a novel stock selection model DeepStockRanker to predict stocks’ future return ranking. Experimental results show that our method is able to extract information from raw data to predict stocks’ future return ranking and achieves much better performance compared with several advanced models. © Springer International Publishing AG, part of Springer Nature 2018.","End-to-end; Learning to rank; LSTM; Stock selection","Big data; Deep learning; Financial data processing; Forecasting; Long short-term memory; End to end; Extract informations; Financial time series; Learning to rank; LSTM; Neural network model; Stock predictions; Stock selections; Data mining"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065427368&doi=10.1109%2fTSP.2019.2907260&partnerID=40&md5=f958ee05acc0f4d49c2232aef3c4fda0","We develop a large-scale deep learning model to predict price movements from limit order book (LOB) data of cash equities. The architecture utilizes convolutional filters to capture the spatial structure of the LOBs as well as long short-term memory modules to capture longer time dependencies. The proposed network outperforms all existing state-of-the-art algorithms on the benchmark LOB dataset [A. Ntakaris, M. Magris, J. Kanniainen, M. Gabbouj, and A. Iosifidis, 'Benchmark dataset for mid-price prediction of limit order book data with machine learning methods,' J. Forecasting, vol. 37, no. 8, 852-866, 2018]. In a more realistic setting, we test our model by using one-year market quotes from the London Stock Exchange, and the model delivers a remarkably stable out-of-sample prediction accuracy for a variety of instruments. Importantly, our model translates well to instruments that were not part of the training set, indicating the model's ability to extract universal features. In order to better understand these features and to go beyond a 'black box' model, we perform a sensitivity analysis to understand the rationale behind the model predictions and reveal the components of LOBs that are most relevant. The ability to extract robust features that translate well to other instruments is an important property of our model, which has many other applications. © 1991-2012 IEEE.","Convolutional neural network; limit order book; LSTM; microstructure market data; time series analysis","Commerce; Convolution; Correlation theory; Deep neural networks; Electronic trading; Financial markets; Forecasting; Memory architecture; Sensitivity analysis; Time series analysis; Convolutional neural network; Limit order book; London Stock Exchange; LSTM; Machine learning methods; Market data; Prediction accuracy; State-of-the-art algorithms; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047019329&doi=10.1109%2fICSESS.2017.8342901&partnerID=40&md5=87c859dd21711c7694134a2e414d1aef","Stock price is one of intricate non-linear dynamic system. Typically, Elman neural network is a local recurrent neural network, having one context layer that memorizes the past states, which is quite fit for resolving time series issues. Given this, this paper takes Elman network to predict the opening price of stock market. Considering that Elman network is limited, this paper adopts self-adapting variant PSO algorithm to optimize the weights and thresholds of network. Afterwards, the optimized data, regarded as initial weight and threshold value, is given to Elman network for training, accordingly the prediction model for opening price of stock market based on self-adapting variant PSO-Elman network is formed. Finally, this paper verifies that model by some stock prices, and compares with BP network and Elman network, so as to draw the result that shows the precision and stability of this predication model both are superior to the traditional neural network. © 2017 IEEE.","Elman network; MATLAB; Self-adapting variant PSO; stock market prediction","Commerce; Costs; Financial markets; Forecasting; Linear control systems; MATLAB; Recurrent neural networks; Elman network; Elman neural network; Local recurrent neural networks; Non-linear dynamic systems; Predication model; Self adapting; Short term prediction; Stock market prediction; Electronic trading"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048469315&doi=10.1109%2fICTAI.2017.00184&partnerID=40&md5=5c4ed2a27e2dd2f3f7530705fc76fd2b","Various techniques have been applied to predict stock market trends. However, the results are not quite satisfactory due to stock market's complexity. Many approaches either lack a clear and reasonable definition of trend or neglect the uniqueness of time attribute in stock data, treating them like other attributes, and use one-size-fits-All models to solve such a typical time-series problem. In this paper, we attempted to exploit the time attribute of stock data to improve prediction accuracy. Firstly, instead of treating data indiscriminately, we used time weight function to carefully assign weights to data according to their temporal nearness towards the data to be predicted. Secondly, the stock trend definitions were formally given by referencing financial theories and best practices. Lastly, Long Short-Term Memory (LSTM) network was customized to discover the underlying temporal dependencies in data. The trials of different time-weighted functions showed that the relation between the importance of data and their time-series is not constant. Instead, it falls within linear and quadratic, roughly a quasilinear function. Equipped with the time-weighted function, LSTM outperformed other models and can be generalized to other stock indexes. In the test with CSI 300 index, we achieved 83.91% in accuracy when fed with the redefined trends. © 2017 IEEE.","LSTM; stock; Time series; Time weighted","Commerce; Financial markets; Forecasting; Time series; CSI 300 indices; LSTM; Prediction accuracy; Quasi-linear functions; stock; Stock trend prediction; Time weighted; Weighted function; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019084658&doi=10.1007%2fs00521-017-3039-z&partnerID=40&md5=3b037a968321059479bfa0a781cdc4a9","Exchange rate forecasting has always been a research hot spot of international finance studies. Deep belief network (DBN) model of deep learning is a new method of predicting the exchange rate data, and the designing of DBN structure and the learning rules of parameters are the most important parts of DBN model. The paper firstly divides the time series data into training and testing sets. By optimizing the DBN parameters, the paper analyses the results of the training analysis and answers how to do node setting. Then, the paper adjusts the number of hidden nodes, inputs nodes and hidden layers, and by using multiple variance analysis, it determines the sensitive range of the node. Finally, the experiments of INR/USD and CNY/USD have proved that compared with the FFNN model, the improved DBN model could better forecast the exchange rate. © 2017, The Natural Computing Applications Forum.","DBN; Deep learning; Exchange rate forecasting","Finance; Forecasting; International trade; Deep belief network (DBN); Deep belief networks; Exchange rate forecasting; Exchange rates; Paper analysis; Time-series data; Training and testing; Variance analysis; Deep learning"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058536539&doi=10.1007%2f978-3-030-05755-8_37&partnerID=40&md5=e6a5099f8436450f9afc6ca8e771ffc6","The Long Short-Term Memory (LSTM) model has been applied in recent years to handle time series data in multiple application domains, such as speech recognition and financial prediction. While the LSTM prediction model has shown promise in anomaly detection in previous research, uncorrelated features can lead to unsatisfactory analysis result and can complicate the prediction model due to the curse of dimensionality. This paper proposes a novel method of clustering and predicting multidimensional aircraft time series. The purpose is to detect anomalies in flight vibration in the form of high dimensional data series, which are collected by dozens of sensors during test flights of large aircraft. The new method is based on calculating the Spearman’s rank correlation coefficient between two series, and on a hierarchical clustering method to cluster related time series. Monotonically similar series are gathered together and each cluster of series is trained to predict independently. Thus series which are uncorrelated or of low relevance do not influence each other in the LSTM prediction model. The experimental results on COMAC’s (Commercial Aircraft Corporation of China Ltd) C919 flight test data show that our method of combining clustering and LSTM model significantly reduces the root mean square error of predicted results. © 2018, Springer Nature Switzerland AG.","Cluster; Correlation coefficient; LSTM; Time series","Aircraft; Chemical detection; Cluster analysis; Clustering algorithms; Forecasting; Mean square error; Speech recognition; Time series; Cluster; Correlation coefficient; Curse of dimensionality; Hierarchical clustering methods; High dimensional data; LSTM; Rank correlation coefficient; Root mean square errors; Long short-term memory"
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905957085&doi=10.1007%2f978-1-4471-4866-1_9&partnerID=40&md5=898e1f5413c4cb204f56e79bba5f3ecb","In this chapter we investigate a typical situation of a corporate treasurer: on an ongoing basis some kind of transaction is performed. This may be a regular monthly investment in equities for a pension plan, or a fixed income placement. It might be a foreign exchange transaction to pay monthly costs in another currency. Or it could be the monthly supply of some commodity, like fuel or metal. All these cases have in common that the treasurer has to choose an appropriate time for the transaction. This is the day on which the price is the most favorable. Ideally, we want to buy at the lowest price within the month, and we also want to invest our money at the highest available interest rate. This problem is complex, because the underlying financial time series are not moving independently. Rather, they are interconnected. In order to truly understand our time series of choice, we have to model other influences as well: equities, currencies, interest rates, commodities, and so on. To achieve this we present a novel recurrent neural network approach: Historically Consistent Neural Networks (HCNN). HCNNs allow to model dynamics of entire markets using a state space equation: st+1=tanh(W⋅st). Here, W represents a weight matrix and st the state of our dynamic system at time t. This iterative formulation easily produces multi step forecasts for several time points into the future. We analyze monthly purchasing decisions for a market of 25 financial time series. This market approximates a world market: it includes various asset classes from Europe, the US, and Asia. Our benchmar, an averaging strategy, shows that using HCNNs to forecast an entry point for ongoing investments results in better prices for every time series in the sample. © Springer-Verlag London 2013.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059099483&partnerID=40&md5=323f1fb1c409772098d812c063577fab","The proceedings contain 33 papers. The special focus in this conference is on Mining Intelligence and Knowledge Exploration. The topics include: Categorical modeling method of intelligent WorkFlow; classification of dengue serotypes using protein sequence based on rule extraction from neural network; orienting social event streams as data stories; software driven optimal design for maintenance man hour; modeling trajectory data as a directed graph; connected cars traffic flow balancing based on classification and calibration; identification and control of a car speed dynamics using artificial intelligence; industry 4.0, intelligent visual assisted picking approach; Detection and mapping of a toxic cloud using UAVs and emergent techniques; Meaningful clusterings of recurrent neural network activations for NLP; convolutional neural networks for multi-class intrusion detection system; wraudit: A tool to transparently monitor web resources’ integrity; using stigmergy to incorporate the time into artificial neural networks; modeling sustainability reporting with ternary attractor neural networks; analysing a periodical and multi-dimensional time series; stock price forecasting over adaptive timescale using supervised learning and receptive fields; Periodically diluted BEGNN model of corruption perception; neural machine translation with recurrent highway networks; a comparative study of methods used in the analysis and prediction of financial data; skin lesion images segmentation: A survey of the state-of-the-art; automatic extraction of structured information from drug descriptions; skin lesion segmentation using enhanced unified Markov random field; texture classification using deep convolutional neural network with ensemble learning; a novel decision tree approach for the handling of time series; reference metadata extraction from Korean research papers.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054328670&partnerID=40&md5=01aeebb42a76f5e1c4b9bc73977eb1e0","The proceedings contain 26 papers. The topics discussed include: evolving fuzzy models for the position control of magnetic levitation systems; comparison of conventional closed-loop controller with an adaptive controller for a disturbed thermodynamic system; granular evolving fuzzy robust feedback linearization; robust evolving control of a two-tanks pilot plant; an implementation of an evolving fuzzy controller; evolving participatory learning fuzzy modeling for financial interval time series forecasting; incremental rule splitting in generalized evolving fuzzy regression models; on-line identification with regularised evolving Gaussian process; introduction of adaptive TS model using recursive Gustafson-Kessel algorithm in short term load forecasting; evolving fuzzy model in fault detection system; autonomous learning for autonomous systems; evolving principal component clustering for 2-D LIDAR data; robust evolving cloud-based controller (RECCo); Self-evolving kernel recursive least squares algorithm for control and prediction; monitoring of vulcano PuraceÁ through seismic signals: description of a real dataset; autonomous learning multi-model classifier of 0-order (ALMMo-0); estimation of moving agents density in 2D space based on LSTM neural network; multi-expert evolving system for objective psychophysiological monitoring and fast discovery of effective personalized therapies; combining evolutionary algorithms and case-based reasoning for learning high-quality shooting strategies in AI birds; online anomaly detection on the Webscope S5 dataset: a comparative study; and modeling and simulation of a small wind turbine system based on PMSG generator.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040242291&partnerID=40&md5=a7a65e443a16cff6d1c61a1d907239d2","The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users’ Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders’ Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040239499&partnerID=40&md5=d2f5bab544cd2ac30e493b31f3af12df","The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users’ Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders’ Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040219278&partnerID=40&md5=c576adf904170bd84e4268344e09d298","The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users’ Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders’ Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904694665&partnerID=40&md5=5f2099ae5bdb0cf5677c6939169b52f4","The proceedings contain 58 papers. The topics discussed include: predicting the outer/inner betastrands in protein beta sheets based on the random forest algorithm; extract features using stacked denoised autoencoder; cancer classification using ensemble of error correcting output codes; early detection method of Alzheimer's disease using EEG signals; tumor clustering using independent component analysis and adaptive affinity propagation; research of training feedforward neural networks based on hybrid chaos particle swarm optimization-back-propagation; training deep Fourier neural networks to fit time-series data; regularized dynamic self organized neural network inspired by the immune algorithm for financial time series prediction; and multi-scale level set method for medical image segmentation without re-initialization.",,
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886999502&partnerID=40&md5=9e3e896c32d8017231baf37816513a07","The proceedings contain 87 papers. The special focus in this conference is on Artificial Neural Networks, Computational Intelligence and Machine Learning. The topics include: Efficient online learning of a non-negative sparse autoencoder; the Markov decision process extraction network; maximal discrepancy for support vector machines; financial time series forecasting with machine learning techniques; introduction to computational intelligence business applications; machine learning analysis and modeling of interest rate curves; modeling contextualized textual knowledge as a long-term working memory; neural competition for motion segmentation; adaptive velocity tuning for visual motion estimation; curvilinear component analysis and Bregman divergences; adaptive matrix distances aiming at optimum regression subspaces; reliability of dimension reduction visualizations of hierarchical structures; mapping without visualizing local default is nonsense; active set training of support vector regressors; fast and good initialization of RBF networks; model learning from weights by adaptive enhanced probabilistic convergent network; autoregressive independent process analysis with missing observations; a pseudoregression formulation of emphasized soft target procedures for classification problems; exploiting hierarchical prediction structures for mixed 2d-3d tracking; hybrid soft computing for PVT properties prediction; approximation of chemical reaction rates in turbulent combustion simulation; asymptotic properties of mixture-of-experts models; towards sub-quadratic learning of probability density models in the form of mixtures of trees; sparse representation of data; highly sparse kernel spectral clustering with predictive out-of-sample extensions; divergence based learning vector quantization; finding correlations in multimodal data using decomposition approaches; deep learning of visual control policies; learning vector quantization for heterogeneous structured data; relational generative topographic map; machine learning techniques based on random projections; solving large regression problems using an ensemble of GPU-accelerated ELMs; a Markovian characterization of redundancy in echo state networks by PCA; random search enhancement of error minimized extreme learning machine; a novel interactive biometric passport photograph alignment system; identifying informative features for ERP speller systems based on RSVP paradigm; a critique of BCM behavior verification for STDP-type plasticity models; an automated SOM clustering based on data topology; a randomized algorithm for spectral clustering; relevance learning in generative topographic maps; extending FSNPC to handle data points with fuzzy class assignments; figure-ground segmentation using metrics adaptation in level set methods; computational intelligence in biomedicine; spectral prototype extraction for dimensionality reduction in brain tumour diagnosis; neural models for the analysis of kidney disease patients; KNN behavior with set-valued attributes; kernel generative topographic mapping; consensus clustering by graph based approach; online speaker diarization with a size-monitored growing neural gas algorithm; a novel two-phase SOM clustering approach to discover visitor interests in a website; image registration by the extended evolutionary self-organizing map; evolution of adaptive center-crossing continuous time recurrent neural networks for biped robot control and free-energy-based reinforcement learning in a partially observable environment.",,
